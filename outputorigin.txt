在目录 '/Users/dxk/Downloads/evrp-eps-main' 中找到的 Python (.py) 代码文件列表 (已排除: __pycache__, checkpoints, data, images, output, results, view_pkl):
============================================================================================================================================

--------------------------------------------------------------------------------
文件路径: /Users/dxk/Downloads/evrp-eps-main/eval_cp4tsn.py
--------------------------------------------------------------------------------

import argparse
import torch
from tqdm import tqdm
from models.tsn.tsn import CP4TSN
from models.tsn.clustered_tsn import CP4ClusteredTSN
from generate_dataset import CIRPDataset

def main(args):
    if args.clustering:
        cp4tsn = CP4ClusteredTSN(num_clusters=args.num_clusters,
                                 cluster_type=args.cluster_type,
                                 merge_duplicated_depots=args.merge_duplicated_depots,
                                 parallel=args.parallel,
                                 num_cpus=args.num_cpus,
                                 time_horizon=args.time_horizon,
                                 dt=args.dt,
                                 vehicle_speed=args.vehicle_speed,
                                 loss_coef=args.loss_coef,
                                 loc_pre_time=args.loc_pre_time,
                                 loc_post_time=args.loc_post_time,
                                 depot_pre_time=args.depot_pre_time,
                                 depot_post_time=args.depot_post_time,
                                 ensure_minimum_charge=args.ensure_minimum_charge,
                                 ensure_minimum_supply=args.ensure_minimum_supply,
                                 random_seed=args.random_seed,
                                 num_search_workers=args.num_search_workers,
                                 log_search_progress=args.log_search_progress,
                                 limit_type=args.limit_type,
                                 time_limit=args.time_limit,
                                 solution_limit=args.solution_limit)
    else:
        cp4tsn = CP4TSN(time_horizon=args.time_horizon,
                        dt=args.dt,
                        vehicle_speed=args.vehicle_speed,
                        loss_coef=args.loss_coef,
                        loc_pre_time=args.loc_pre_time,
                        loc_post_time=args.loc_post_time,
                        depot_pre_time=args.depot_pre_time,
                        depot_post_time=args.depot_post_time,
                        ensure_minimum_charge=args.ensure_minimum_charge,
                        ensure_minimum_supply=args.ensure_minimum_supply,
                        random_seed=args.random_seed,
                        num_search_workers=args.num_search_workers,
                        log_search_progress=args.log_search_progress,
                        limit_type=args.limit_type,
                        time_limit=args.time_limit,
                        solution_limit=args.solution_limit)

    dataset = CIRPDataset().load_from_pkl(args.dataset_path, load_dataopts=False)
    dataloader = torch.utils.data.DataLoader(dataset,
                                             batch_size=None,
                                             shuffle=False,
                                             num_workers=args.num_workers)
    
    for batch_id, batch in enumerate(tqdm(dataloader)):
        status = cp4tsn.solve(batch, log_fname=args.log_fname)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    # general settings
    parser.add_argument("--random_seed", type=int, default=1234)
    parser.add_argument("--num_search_workers", type=int, default=4)
    parser.add_argument("--log_search_progress", action="store_true")
    parser.add_argument("--log_fname")

    # dataset settings
    parser.add_argument("--dataset_path", type=str, required=True)
    parser.add_argument("--num_workers", type=int, default=4)

    # environment settings
    parser.add_argument("--time_horizon", type=int, default=12)
    parser.add_argument("--dt", type=float, default=1.)
    parser.add_argument("--vehicle_speed", type=float, default=41.)
    parser.add_argument("--loss_coef", type=int, default=100)
    parser.add_argument("--loc_pre_time", type=float, default=0.5)
    parser.add_argument("--loc_post_time", type=float, default=0.5)
    parser.add_argument("--depot_pre_time", type=float, default=0.17)
    parser.add_argument("--depot_post_time", type=float, default=0.17)
    parser.add_argument("--ensure_minimum_charge", action="store_true")
    parser.add_argument("--ensure_minimum_supply", action="store_true")
    parser.add_argument("--limit_type", type=str, default=None)
    parser.add_argument("--time_limit", type=float, default=60.)
    parser.add_argument("--solution_limit", type=int, default=100)

    # model settings
    parser.add_argument("--clustering", action="store_true")
    parser.add_argument("--cluster_type", type=str, default="kmeans")
    parser.add_argument("--merge_duplicated_depots", action="store_true")
    parser.add_argument("--num_clusters", type=int, default=None)
    parser.add_argument("--parallel", action="store_true")
    parser.add_argument("--num_cpus", type=int, default=4)
    args = parser.parse_args()
    main(args)


--------------------------------------------------------------------------------
文件路径: /Users/dxk/Downloads/evrp-eps-main/valid.py
--------------------------------------------------------------------------------

import os
import subprocess
import argparse
from utils.util import set_device
from eval import eval

def valid(args: argparse.Namespace) -> None:
    # compare each epoch on validation datasets
    best_epoch = 0
    min_cost   = 1e+9 # a large value
    for epoch in range(args.max_epoch+1):
        print(f"Evaluating the model at epoch{epoch} (currently best epoch is {best_epoch}: cost={min_cost})", flush=True)
        # load a trained model
        model_path = f"{args.model_dir}/model_epoch{epoch}.pth"
        res = eval(dataset_path=args.dataset_path,
                   eval_batch_size=args.eval_batch_size,
                   model_type="rl",
                   model_path=model_path,
                   decode_type="greedy",
                   penalty_coef=args.penalty_coef,
                   vehicle_speed=args.vehicle_speed,
                   wait_time=args.wait_time,
                   time_horizon=args.time_horizon,
                   random_seed=1234, # dummy seed. we here use greedy decode, so random seed will not affect the results.
                   gpu=args.gpu,
                   num_workers=args.num_workers)
        cost = res["avg_obj"]

        # if the current epoch is better than previous epochs
        if min_cost > cost:
            best_epoch = epoch
            min_cost   = cost

    # save the best epoch
    model_path = f"{args.model_dir}/model_epoch{best_epoch}.pth"
    save_path  = f"{args.model_dir}/model_bestepoch.pth"
    subprocess.run(f"cp {model_path} {save_path}", shell=True)


if __name__ == "__main__":
    import datetime
    now = datetime.datetime.now()
    parser = argparse.ArgumentParser()
    # general settings
    parser.add_argument("--gpu",              type=int, default=-1)
    parser.add_argument("--num_workers",      type=int, default=4)
    parser.add_argument("--output_dir",       type=str, default=f"results/results_{now.strftime('%Y%m%d_%H%M%S')}")
    parser.add_argument("--log_fname",        type=str, default=None)

    # dataset settings
    parser.add_argument("--dataset_path",    type=str, required=True)
    parser.add_argument("--eval_batch_size", type=int, default=256)

    # model settings
    parser.add_argument("--model_dir",    type=str,   required=True)
    parser.add_argument("--penalty_coef", type=float, default=100)
    parser.add_argument("--max_epoch",    type=int,   default=100)

    # other parameters
    parser.add_argument("--vehicle_speed", type=float, default=41.0)
    parser.add_argument("--wait_time",     type=float, default=0.5)
    parser.add_argument("--time_horizon",  type=float, default=12.0)

    args = parser.parse_args()
    os.makedirs(args.output_dir, exist_ok=True)
    if args.log_fname is not None:
        os.makedirs(os.path.dirname(args.log_fname), exist_ok=True)
    valid(args)


--------------------------------------------------------------------------------
文件路径: /Users/dxk/Downloads/evrp-eps-main/generate_dataset.py
--------------------------------------------------------------------------------

import os
from tqdm import tqdm
import torch
from torch.utils.data import Dataset
import numpy as np
from utils.util import save_dataset, load_dataset
import random
import json
import argparse
import _pickle as cpickle
from multiprocessing import Pool

class CIRPDataset(Dataset):
    def __init__(self):
        super().__init__()
        self.dataset = []
        self.size = 0
        self.opts = None

    def __len__(self):
        return self.size
    
    def __getitem__(self, idx):
        return self.dataset[idx]
    
    def generate(self,
                 num_samples: int, 
                 num_locs: int, 
                 num_depots: int, 
                 num_vehicles: int, 
                 vehicle_cap: float, 
                 vehicle_discharge_rate: float, 
                 depot_discharge_rate: list,
                 discharge_lim_ratio: float = 0.1,
                 cap_ratio: float = 0.8,
                 grid_scale: float = 100.0,
                 random_seed: int = 1234):
        """
        please specify the random_seed usually. specify nothing when generating eval dataset in the rollout baseline.

        Paramters
        ---------
        
        Returns
        -------
        """
        self.dataset = self.generate_dataset(num_samples=num_samples,
                                             num_locs=num_locs,
                                             num_depots=num_depots,
                                             num_vehicles=num_vehicles,
                                             vehicle_cap=vehicle_cap,
                                             vehicle_discharge_rate=vehicle_discharge_rate,
                                             depot_discharge_rate=depot_discharge_rate,
                                             discharge_lim_ratio=discharge_lim_ratio,
                                             cap_ratio=cap_ratio,
                                             grid_scale=grid_scale,
                                             random_seed=random_seed)
        self.size = len(self.dataset)
        return self

    def load_from_pkl(self,
                      dataset_path: str,
                      load_dataopts: bool = True,
                      max_load_size: int = -1):
        """
        Paramters
        ---------
        dataset_path: str
            path to a dataset
        load_dataopts: bool
            whether or not options(argparse) of datasets are loaded
        """
        assert os.path.splitext(dataset_path)[1] == ".pkl"
        if max_load_size > 0:
            self.dataset = load_dataset(dataset_path)[:max_load_size]
        else:
            self.dataset = load_dataset(dataset_path)
        self.size = len(self.dataset)
        if load_dataopts:
            self.opts = argparse.ArgumentParser()
            data_params_dir = os.path.split(dataset_path)[0]
            with open(f"{data_params_dir}/data_cmd_args.json", "r") as f:
                self.opts.__dict__ = json.load(f)
        return self

    def generate_instance(self,
                          num_locs: int,
                          num_depots: int, 
                          num_vehicles: int, 
                          vehicle_cap: float,
                          vehicle_discharge_rate: float,
                          depot_discharge_rate_candidates: float, 
                          discharge_lim_ratio: float = 0.1,
                          cap_ratio: float = 0.8,
                          grid_scale: float = 100.0,
                          random_seed: int = None):
        if random_seed is not None:
            torch.manual_seed(random_seed)
            random.seed(random_seed)

        coord_dim = 2
        num_nodes = num_locs + num_depots
        #-----------------------
        # vehicles (homogeneous)
        #-----------------------
        vehicle_cap = [vehicle_cap for _ in range(num_vehicles)] # [num_vehicle]
        vehicle_initial_position_id = torch.randint(num_locs, num_nodes, (num_vehicles, )) # [num_vehicles]
        vehicle_discharge_rate = torch.FloatTensor([vehicle_discharge_rate for _ in range(num_vehicles)])
        vehicle_consump_rate = torch.FloatTensor([0.161 * grid_scale for _ in range(num_vehicles)]) # 
        #-----------
        # locations
        #-----------
        # TODO : wide-range capacity candidates
        capacity_consump = {
            2.34: [0.6, 0.7],
            11.7: [1.1, 1.5, 1.7],
            35.1: np.arange(1.1, 6.0, 0.1).tolist(),
            46.8: np.arange(1.1, 6.0, 0.1).tolist()
        }
        weights = [6, 9, 51, 59]
        loc_coords = torch.FloatTensor(num_locs, coord_dim).uniform_(0, 1) # [num_locs x coord_dim]
        loc_cap = torch.FloatTensor(random.choices(list(map(lambda x: round(x, 2), capacity_consump.keys())), k=num_locs, weights=weights)) # [num_locs]
        loc_initial_battery = (torch.rand(num_locs) * .5 + .5) * loc_cap  # 50 - 100% of the capacity [num_locs]
        # conditional probability
        loc_consump_list = []
        for cap in loc_cap:
            loc_consump_list.append(random.choices(capacity_consump[round(cap.item(), 2)], k=1))
        loc_consump_rate = torch.FloatTensor(loc_consump_list).squeeze(1) # [num_locs]
        #--------
        # depots
        #--------
        depot_coords = torch.FloatTensor(num_depots, coord_dim).uniform_(0, 1) # [num_depots x coord_dim]
        depot_discharge_rate = torch.FloatTensor(random.choices(depot_discharge_rate_candidates, k=num_depots, weights=[0.2, 0.8])) # [num_depots]
        # ensure num. of depots whose discharge = 50 is more than 50 %
        min_depot_count = int(0.5 * len(depot_discharge_rate))
        if torch.count_nonzero(depot_discharge_rate > 10) < min_depot_count:
            idx = random.sample(range(len(depot_discharge_rate)), k=min_depot_count)
            depot_discharge_rate[idx] = 50.0
           
        return {
            "grid_scale": torch.FloatTensor([grid_scale]),
            "loc_coords": loc_coords,
            "loc_cap": loc_cap * cap_ratio,
            "loc_consump_rate": loc_consump_rate,
            "loc_initial_battery": loc_initial_battery * cap_ratio,
            "depot_coords": depot_coords,
            "depot_discharge_rate": depot_discharge_rate,
            "vehicle_cap": torch.FloatTensor(vehicle_cap) * cap_ratio,
            "vehicle_initial_position_id": vehicle_initial_position_id,
            "vehicle_discharge_rate": vehicle_discharge_rate,
            "vehicle_consump_rate": vehicle_consump_rate,
            "vehicle_discharge_lim": discharge_lim_ratio * torch.FloatTensor(vehicle_cap)
        }

    def generate_dataset(self,
                         num_samples: int, 
                         num_locs: int, 
                         num_depots: int, 
                         num_vehicles: int, 
                         vehicle_cap: float, 
                         vehicle_discharge_rate: float, 
                         depot_discharge_rate: list,
                         discharge_lim_ratio: float = 0.1,
                         cap_ratio: float = 0.8,
                         grid_scale: float = 100.0,
                         random_seed: int = 1234):
        seeds = random_seed + np.arange(num_samples)
        return [
            self.generate_instance(num_locs=num_locs,
                                   num_depots=num_depots,
                                   num_vehicles=num_vehicles,
                                   vehicle_cap=vehicle_cap,
                                   vehicle_discharge_rate=vehicle_discharge_rate,
                                   depot_discharge_rate_candidates=depot_discharge_rate, 
                                   discharge_lim_ratio=discharge_lim_ratio, 
                                   cap_ratio=cap_ratio,
                                   grid_scale=grid_scale,
                                   random_seed=seed)
            for seed in tqdm(seeds)
        ]

    def generate_dataset_para(self,
                              num_samples: int, 
                              num_locs: int, 
                              num_depots: int, 
                              num_vehicles: int, 
                              vehicle_cap: float, 
                              vehicle_discharge_rate: float, 
                              depot_discharge_rate: list,
                              discharge_lim_ratio: float = 0.1,
                              cap_ratio: float = 0.8,
                              grid_scale: float = 100.0,
                              random_seed: int = 1234,
                              num_cpus: int = 4):
        seeds = random_seed + np.arange(num_samples)
        with Pool(num_cpus) as pool:
            dataset = list(pool.starmap(self.generate_instance, tqdm([(num_locs, 
                                                                       num_depots,
                                                                       num_vehicles,
                                                                       vehicle_cap,
                                                                       vehicle_discharge_rate,
                                                                       depot_discharge_rate,
                                                                       discharge_lim_ratio,
                                                                       cap_ratio,
                                                                       grid_scale,
                                                                       seed) for seed in seeds], total=len(seeds))))
        return dataset

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--random_seed", type=int, default=1234)
    parser.add_argument("--save_dir", type=str, required=True)
    parser.add_argument("--type", type=str, nargs="*", default=["all"])
    parser.add_argument("--num_samples", type=int, nargs="*", default=[1280000, 10000, 10000])
    parser.add_argument("--num_depots", type=int, default=12)
    parser.add_argument("--num_locs", type=int, default=50)
    parser.add_argument("--num_vehicles", type=int, default=12)
    parser.add_argument("--vehicle_cap", type=float, default=60.0) # all the vehicles have the same capacity
    parser.add_argument("--vehicle_discharge_rate", type=float, default=10.0)
    parser.add_argument("--depot_discharge_rate", type=float, nargs="*", default=[3.0, 50.0])
    parser.add_argument("--cap_ratio", type=float, default=0.8)
    parser.add_argument("--discharge_lim_ratio", type=float, default=0.1)
    parser.add_argument("--grid_scale", type=float, default=100.0)
    parser.add_argument("--parallel", action="store_true")
    parser.add_argument("--num_cpus", type=int, default=4)
    
    args = parser.parse_args()
    os.makedirs(args.save_dir, exist_ok=True)
    
    # validation check
    if args.type[0] == "all":
        assert len(args.num_samples) == 3
    else:
        assert len(args.type) == len(args.num_samples)
    num_samples = np.sum(args.num_samples)

    if args.parallel:
        dataset = CIRPDataset().generate_dataset_para(num_samples=num_samples,
                                                      num_locs=args.num_locs,
                                                      num_depots=args.num_depots,
                                                      num_vehicles=args.num_vehicles,
                                                      vehicle_cap=args.vehicle_cap,
                                                      vehicle_discharge_rate=args.vehicle_discharge_rate,
                                                      depot_discharge_rate=args.depot_discharge_rate,
                                                      discharge_lim_ratio=args.discharge_lim_ratio,
                                                      cap_ratio=args.cap_ratio,
                                                      grid_scale=args.grid_scale,
                                                      random_seed=args.random_seed,
                                                      num_cpus=args.num_cpus)
    else:
        dataset = CIRPDataset().generate_dataset(num_samples=num_samples,
                                                num_locs=args.num_locs,
                                                num_depots=args.num_depots,
                                                num_vehicles=args.num_vehicles,
                                                vehicle_cap=args.vehicle_cap,
                                                vehicle_discharge_rate=args.vehicle_discharge_rate,
                                                depot_discharge_rate=args.depot_discharge_rate,
                                                discharge_lim_ratio=args.discharge_lim_ratio,
                                                cap_ratio=args.cap_ratio,
                                                grid_scale=args.grid_scale,
                                                random_seed=args.random_seed)
    if args.type[0] == "all":
        types = ["train", "valid", "eval"]
    else:
        types = args.type
    num_sample_list = args.num_samples
    num_sample_list.insert(0, 0)
    start = 0
    for i, type_name in enumerate(types):
        start += num_sample_list[i]
        end = start + num_sample_list[i+1]
        divided_datset = dataset[start:end]
        save_dataset(divided_datset, f"{args.save_dir}/{type_name}_dataset.pkl")
    
    # save paramters
    with open(f'{args.save_dir}/data_cmd_args.json', 'w') as f:
        json.dump(args.__dict__, f, indent=2)


--------------------------------------------------------------------------------
文件路径: /Users/dxk/Downloads/evrp-eps-main/visualize.py
--------------------------------------------------------------------------------

from utils.util import load_dataset
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import matplotlib.animation as animation
import torch
import numpy as np
from torchvision import transforms
from PIL import Image
from matplotlib.offsetbox import OffsetImage, AnnotationBbox
from matplotlib import patches
from copy import copy

DPI = 150
VIS_OFFSET = 0.02
BATT_OFFSET = 0.02

def add_base(x, y, ratio, ax):
    width = 0.01
    height = 0.015
    height_mod = ratio * height
    if ratio > 0.5:
        battery_color = "limegreen"
    elif ratio > 0.3:
        battery_color = "gold"
    else:
        battery_color = "red"
    
    if ratio < 1e-9:
        ec = "red"
    else:
        ec = "black"

    frame = patches.Rectangle(xy=(x-width/2, y-height/2), width=width, height=height, fill=False, ec=ec)
    battery = patches.Rectangle(xy=(x-width/2, y-height/2), width=width, height=height_mod, facecolor=battery_color, linewidth=.5, ec="black")
    ax.add_patch(battery)
    ax.add_patch(frame)

def add_vehicle(x, y, ratio, color, ax, offst=0.0):
    # vehicle_battery
    # ratio = 0.4
    width = 0.015
    height = 0.01
    width_mod = ratio * width
    if ratio < 1e-9:
        ec = "red"
    else:
        ec = "black"
    frame = patches.Rectangle(xy=(x-width/2, y-height/2+offst+BATT_OFFSET), width=width, height=height, fill=False, ec=ec)
    battery = patches.Rectangle(xy=(x-width/2, y-height/2+offst+BATT_OFFSET), width=width_mod, height=height, facecolor=color, linewidth=.5, ec="black")
    ax.add_patch(battery)
    ax.add_patch(frame)

    # vehicle
    original_img = plt.imread("images/ev_image.png")
    vehicle_img = np.where(original_img == (1., 1., 1., 1.), (color[0], color[1], color[2], color[3]), original_img)
    vehicle_img = OffsetImage(vehicle_img, zoom=0.1)
    ab = AnnotationBbox(vehicle_img, (x, y+offst), xycoords='data', frameon=False)
    ax.add_artist(ab)


def visualize_tour(dataset_path, tour_path, save_dir, instance, anim_type):
    dataset = load_dataset(dataset_path)
    tours = load_dataset(tour_path)
    data = dataset[instance]
    tour = tours[instance]

    # node information
    loc_coords = data["loc_coords"] # [num_locs x coord_dim]
    depot_coords = data["depot_coords"] # [num_depots x coord_dim]
    coords = torch.cat((loc_coords, depot_coords), 0) # [num_nodes x coord_dim]
    x_loc = loc_coords[:, 0]; y_loc = loc_coords[:, 1]
    x_depot = depot_coords[:, 0]; y_depot = depot_coords[:, 1]

    num_locs      = len(x_loc)
    num_depots    = len(x_depot)
    num_vehicles  = len(tour)
    vehicle_steps = [0] * num_vehicles
    vehicle_travel_time    = np.zeros(num_vehicles)
    vehicle_charge_time    = np.zeros(num_vehicles)
    vehicle_unavail_time   = np.zeros(num_vehicles)
    estimated_unavail_time = np.zeros(num_vehicles)
    vehicle_phase = ["move" for _ in range(num_vehicles)]
    finished = ["end" for _ in range(num_vehicles)]
    vehicle_visit = np.zeros((num_vehicles, 2, 2)) # stores x_curr, y_curr, x_next, y_next
    vehicle_max_steps = [len(tour[vehicle_id]) for vehicle_id in range(num_vehicles)]
    loc_battery = data["loc_initial_battery"] # [num_locs]
    loc_cap = data["loc_cap"] # [num_locs]
    loc_consump_rate = data["loc_consump_rate"] # [num_locs]
    vehicle_discharge_rate = data["vehicle_discharge_rate"] # [num_vehicles]
    vehicle_position = np.zeros(num_vehicles).astype(int) # [num_vehicles]
    vehicle_battery = data["vehicle_cap"].clone() # [num_vehicles]
    vehicle_cap = data["vehicle_cap"].clone() # [num_vehicles]
    depot_discharge_rate = data["depot_discharge_rate"]
    curr_time = 0.0
    
    # select color map
    if num_vehicles <= 10:
        cm_name = "tab10"
    elif num_vehicles <= 20:
        cm_name = "tab20"
    else:
        assert False
    cmap = cm.get_cmap(cm_name)

    #----------------------------
    # visualize the initial step
    #----------------------------
    # initialize a fig instance
    fig = plt.figure(figsize=(10, 10))
    ax = fig.add_subplot(111)

    # add locations & depots
    for id in range(num_locs):
        ratio = loc_battery[id] / loc_cap[id]
        add_base(x_loc[id], y_loc[id], ratio, ax)
    ax.scatter(x_depot, y_depot, marker="*", c="black", s=100, zorder=3)

    # initial vehicle assignment
    NODE_ID = 0; TRAVEL_TIME = 1; CHARGE_TIME = 2
    for i in range(num_vehicles):
        vehicle_steps[i] += 1
        vehicle_position[i] = tour[i][vehicle_steps[i]][NODE_ID]
        vehicle_visit[i, 0, 0] = coords[tour[i][vehicle_steps[i]-1][NODE_ID], 0] # x_curr
        vehicle_visit[i, 0, 1] = coords[tour[i][vehicle_steps[i]-1][NODE_ID], 1] # y_curr
        vehicle_visit[i, 1, 0] = coords[tour[i][vehicle_steps[i]][NODE_ID], 0] # x_next
        vehicle_visit[i, 1, 1] = coords[tour[i][vehicle_steps[i]][NODE_ID], 1] # y_next
        ax.plot(vehicle_visit[i, :, 0], vehicle_visit[i, :, 1], zorder=0, alpha=0.5, linestyle="--", color=cmap(i))
        vehicle_travel_time[i] = tour[i][vehicle_steps[i]][TRAVEL_TIME]
        vehicle_charge_time[i] = tour[i][vehicle_steps[i]][CHARGE_TIME]
        vehicle_unavail_time[i] = vehicle_travel_time[i]
        estimated_unavail_time[i] = vehicle_travel_time[i]
        # add a vehicle to image
        ratio = vehicle_battery[i] / vehicle_cap[i]
        add_vehicle(vehicle_visit[i, 0, 0], vehicle_visit[i, 0, 1], ratio, cmap(i), ax, VIS_OFFSET)

    # plt.savefig(f"{save_dir}/vis/png/tour_test.png")
    ax.set_title(f"current_time = {curr_time:.3f}")
    plt.xlim(-0.05, 1.05); plt.ylim(-0.05, 1.05)
    plt.savefig(f"{save_dir}/vis/png/tour_test0.png", dpi=DPI)
    plt.close()

    #-------------------------------
    # visualize the subseqent steps
    #-------------------------------
    total_steps = 1
    all_finished = False 
    while not all_finished:
        # select next vehicle
        next_vehicle_id = np.argmin(vehicle_unavail_time)
        i = next_vehicle_id

        # update time
        elapsed_time = vehicle_unavail_time[i].copy()
        curr_time += vehicle_unavail_time[i]
        vehicle_unavail_time -= vehicle_unavail_time[i]
        vehicle_unavail_time = vehicle_unavail_time.clip(0.0)

        # initialize a fig instance
        fig = plt.figure(figsize=(10, 10))
        ax = fig.add_subplot(111)

        # add locations & depots
        charged_loc = []
        for vehicle_id in range(num_vehicles):
            loc_id = vehicle_position[vehicle_id]
            at_loc = loc_id < num_locs
            charging = vehicle_phase[vehicle_id] == "charge"
            if at_loc & charging:
                loc_battery[loc_id] += vehicle_discharge_rate[vehicle_id] * elapsed_time
                vehicle_battery[vehicle_id] -= vehicle_discharge_rate[vehicle_id] * elapsed_time
                vehicle_battery[vehicle_id] = vehicle_battery[vehicle_id].clip(0.0)
                ratio = loc_battery[loc_id] / loc_cap[loc_id]
                add_base(x_loc[loc_id], y_loc[loc_id], ratio, ax)
                charged_loc.append(loc_id)
            if (not at_loc) & charging:
                vehicle_battery[vehicle_id] += depot_discharge_rate[loc_id - num_locs] * elapsed_time

        for id in range(num_locs):
            if not (id in charged_loc):
                loc_battery[id] -= loc_consump_rate[id] * elapsed_time
                loc_battery[id] = loc_battery[id].clamp(0.0)
                ratio = loc_battery[id] / loc_cap[id]
                add_base(x_loc[id], y_loc[id], ratio, ax)
        # ax.scatter(x_loc, y_loc, marker="o", c="black", zorder=3)
        ax.scatter(x_depot, y_depot, marker="*", c="black", s=100, zorder=3)

        #-----------------------------------
        # visualization of selected vehicle
        #-----------------------------------
        # add the path
        if vehicle_phase[i] == "move":
            ax.plot(vehicle_visit[i, :, 0], vehicle_visit[i, :, 1], zorder=0, linestyle="-", color=cmap(i))
        # add selected vehicle to image
        ratio = vehicle_battery[i] / vehicle_cap[i]
        add_vehicle(vehicle_visit[i, 1, 0], vehicle_visit[i, 1, 1], ratio, cmap(i), ax, VIS_OFFSET)

        #---------------------------------
        # visualization of other vehicles
        #---------------------------------
        for k in range(num_vehicles):
            if k != i:
                x_st  = vehicle_visit[k, 0, 0]; y_st  = vehicle_visit[k, 0, 1]
                x_end = vehicle_visit[k, 1, 0]; y_end = vehicle_visit[k, 1, 1]
                if vehicle_phase[k] == "move":
                    progress = 1.0 - (vehicle_unavail_time[k] / estimated_unavail_time[k])
                    x_curr = progress * (x_end - x_st) + x_st
                    y_curr = progress * (y_end - y_st) + y_st
                    ax.plot([x_st, x_curr], [y_st, y_curr], zorder=0, linestyle="-", color=cmap(k))
                    ax.plot([x_curr, x_end], [y_curr, y_end], zorder=0, alpha=0.5, linestyle="--", color=cmap(k))
                    x_vehicle = x_curr; y_vehicle = y_curr
                    vis_offst = 0.0
                else:
                    x_vehicle = x_end; y_vehicle = y_end
                    vis_offst = VIS_OFFSET
                # add other vehicles to image
                ratio = vehicle_battery[k] / vehicle_cap[k]
                add_vehicle(x_vehicle, y_vehicle, ratio, cmap(k), ax, vis_offst)

        #--------------
        # update state
        #--------------
        if vehicle_phase[i] == "move":
            vehicle_unavail_time[i] = vehicle_charge_time[i].copy()
            estimated_unavail_time[i] = vehicle_charge_time[i].copy()
            if vehicle_steps[next_vehicle_id] >= vehicle_max_steps[next_vehicle_id] - 1:
                vehicle_phase[i] = "end"
                vehicle_unavail_time[i] = 1e+9
            else:
                vehicle_phase[i] = "charge"
        elif vehicle_phase[i] == "charge":
            vehicle_steps[next_vehicle_id] += 1
            vehicle_position[i] = tour[i][vehicle_steps[i]][NODE_ID]
            vehicle_travel_time[i] = tour[i][vehicle_steps[i]][TRAVEL_TIME]
            vehicle_charge_time[i] = tour[i][vehicle_steps[i]][CHARGE_TIME]
            vehicle_unavail_time[i]   = vehicle_travel_time[i].copy()
            estimated_unavail_time[i] = vehicle_travel_time[i].copy()
            vehicle_visit[i, 0, 0] = coords[tour[i][vehicle_steps[i]-1][NODE_ID], 0]
            vehicle_visit[i, 0, 1] = coords[tour[i][vehicle_steps[i]-1][NODE_ID], 1]
            vehicle_visit[i, 1, 0] = coords[tour[i][vehicle_steps[i]][NODE_ID], 0]
            vehicle_visit[i, 1, 1] = coords[tour[i][vehicle_steps[i]][NODE_ID], 1]
            vehicle_phase[i] = "move"

        if elapsed_time < 1e-9:
            plt.close()
            all_finished = not (vehicle_phase != finished)
            continue
        else:
            ax.set_title(f"current_time = {curr_time:.3f}")
            plt.xlim(-0.05, 1.05); plt.ylim(-0.05, 1.05)
            plt.savefig(f"{save_dir}/vis/png/tour_test{total_steps}.png", dpi=DPI)
            plt.close()
        # plt.savefig(f"{save_dir}/vis/png/tour_test.png")

        total_steps += 1
        all_finished = not (vehicle_phase != finished)

    # generate a gif from png files 
    gif_fig = plt.figure(figsize=(10, 10))
    pic_list = [f"{save_dir}/vis/png/tour_test{i}.png" for i in range(total_steps)]
    ims = []
    for i in range(len(pic_list)):
        im = Image.open(pic_list[i])
        ims.append([plt.imshow(im)])
    plt.axis("off")
    gif_fig.subplots_adjust(left=0, right=1, bottom=0, top=1)
    gif = animation.ArtistAnimation(gif_fig, ims, interval=500, repeat_delay=5000)
    if anim_type == "gif":
        gif.save(f"{save_dir}/vis/test.gif", writer="pillow")
    else:
        gif.save(f"{save_dir}/vis/test.mp4", writer="ffmpeg")

if __name__ == "__main__":
    import argparse
    import os
    parser = argparse.ArgumentParser()
    parser.add_argument("--dataset_path", type=str, required=True)
    parser.add_argument("--tour_path", type=str, required=True)
    parser.add_argument("--save_dir", type=str, required=True)
    parser.add_argument("--instance", type=int, default=0)
    parser.add_argument("--anim_type", type=str, default="gif")
    args = parser.parse_args()
    os.makedirs(f"{args.save_dir}/vis/png", exist_ok=True)
    visualize_tour(args.dataset_path, args.tour_path, args.save_dir, args.instance, args.anim_type)


--------------------------------------------------------------------------------
文件路径: /Users/dxk/Downloads/evrp-eps-main/train.py
--------------------------------------------------------------------------------

import argparse
import datetime
import json
import os
import torch
import torch.optim as optim
from tqdm import tqdm
from models.am import AM4CIRP
import models.baselines as rl_baseline
from utils.util import set_device, fix_seed
from generate_dataset import CIRPDataset

def main(args: argparse.Namespace) -> None:
    # save parameter settings
    if os.path.exists(args.checkpoint_dir):
        response = input(f"The directory '{args.checkpoint_dir}' already exists. Do you want to overwrite it? [y/n]: ").strip().lower()
        if response != 'y':
            assert False, "If you don't want to overwrite the checkpoint directory, please specify another checkpoint_dir."
    os.makedirs(args.checkpoint_dir, exist_ok=True)
    with open(f'{args.checkpoint_dir}/cmd_args.dat', 'w') as f:
        json.dump(args.__dict__, f, indent=2)

    # set random seed
    fix_seed(args.random_seed)
    
    # device settings (gpu or cpu)
    use_cuda, device = set_device(args.gpu)

    # dataset
    dataset = CIRPDataset().load_from_pkl(args.dataset_path)
    dataloader = torch.utils.data.DataLoader(dataset,
                                             batch_size=args.batch_size,
                                             shuffle=True,
                                             num_workers=args.num_workers)

    # model & optimizer
    model = AM4CIRP(loc_dim=args.loc_dim,
                    depot_dim=args.depot_dim, 
                    vehicle_dim=args.vehicle_dim,
                    emb_dim=args.emb_dim,
                    num_heads=args.num_heads,
                    num_enc_layers=args.num_enc_layers,
                    dropout=args.dropout,
                    device=device)
    if use_cuda:
        model.to(device)
    model_optimizer = optim.Adam(model.parameters(), lr=args.lr)
    
    # baseline for the REINFOCE
    if args.baseline == "rollout":
        baseline = rl_baseline.RolloutBaseline(model, dataset.opts, args, device=device)
    elif args.baseline == "exponential":
        baseline = rl_baseline.ExponentialBaseline(args.beta, device=device)
    else:
        raise TypeError("Invalid baseline type :(")

    # train
    model.train()
    for epoch in range(args.epochs+1):
        # save the current checkpoint
        if epoch % args.checkpoint_interval == 0:
            print(f"Epoch {epoch}: saving a model to {args.checkpoint_dir}/model_epoch{epoch}.pth...", end="", flush=True)
            torch.save(model.cpu().state_dict(), f"{args.checkpoint_dir}/model_epoch{epoch}.pth")
            model.to(device)
            print("done.")

        with tqdm(dataloader) as tq:
            for batch_id, batch in enumerate(tq):
                if use_cuda:
                    batch = {key: value.to(device) for key, value in batch.items()}
                # add options
                batch.update({
                    "time_horizon":  args.time_horizon,
                    "vehicle_speed": args.vehicle_speed,
                    "wait_time":     args.wait_time
                })

                # output tours
                if args.debug:
                    rewards, logprobs, reward_dict, tours = model(batch, "sampling", fname=f"{batch_id}")
                    print(f"tour_length: {reward_dict['tour_length'].mean().item()}")
                    print(f"penalty: {reward_dict['penalty'].mean().item()}")
                    print(f"tour: {tours[0][0]}")
                else:
                    rewards, logprobs = model(batch, "sampling")

                # calc baseline
                baseline_v, _ = baseline.eval(batch, rewards)

                # calc loss
                advantage = (rewards - baseline_v).detach() # [batch_size]
                loss = (advantage * logprobs).mean() # batch-wise mean [1]
                
                # backprop
                model_optimizer.zero_grad()
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip_grad_norm, norm_type=2)
                model_optimizer.step()
                tq.set_postfix(cost=rewards.mean().item())

        # logging
        # if epoch % args.log_interval == 0:
        #     print()

        baseline.epoch_callback(model, epoch)


if __name__ == "__main__":
    now = datetime.datetime.now()
    parser = argparse.ArgumentParser()
    #------------------
    # general settings
    #------------------
    parser.add_argument("--random_seed",    type=int, default=1234)
    parser.add_argument("--gpu",            type=int, default=-1)
    parser.add_argument("--num_workers",    type=int, default=4)
    parser.add_argument("--checkpoint_dir", type=str, default=f"checkpoints/model_{now.strftime('%Y%m%d_%H%M%S')}")
    parser.add_argument("--debug",          action="store_true")

    #------------------
    # dataset settings
    #------------------
    parser.add_argument("--dataset_path", type=str, required=True)
    parser.add_argument("--problem",      type=str, default="cirp")
    parser.add_argument("--coord_dim",    type=int, default=2)
    parser.add_argument("--num_samples",  type=int, default=1)
    parser.add_argument("--num_depots",   type=int, default=1)
    parser.add_argument("--num_locs",     type=int, default=20)
    parser.add_argument("--num_vehicles", type=int, default=3)
    parser.add_argument("--vehicle_cap",  type=int, default=10)

    #-------------------
    # training settings
    #-------------------
    parser.add_argument("--batch_size",          type=int,   default=128)
    parser.add_argument("--epochs",              type=int,   default=100)
    parser.add_argument("--log_interval",        type=int,   default=20)
    parser.add_argument("--checkpoint_interval", type=int,   default=1)
    parser.add_argument("--lr",                  type=float, default=1e-4)
    parser.add_argument("--clip_grad_norm",      type=float, default=1.0)
    parser.add_argument("--dropout",             type=float, default=0.2)
    # for greedy baseline
    parser.add_argument("--num_greedy_samples",  type=int,   default=1280)
    parser.add_argument("--greedy_batch_size",   type=int,   default=128)

    #----------------
    # model settings
    #----------------
    parser.add_argument("--loc_dim",        type=int, default=7)
    parser.add_argument("--depot_dim",      type=int, default=4)
    parser.add_argument("--vehicle_dim",    type=int, default=11)
    parser.add_argument("--emb_dim",        type=int, default=128)
    parser.add_argument("--num_heads",      type=int, default=8)
    parser.add_argument("--num_enc_layers", type=int, default=2)

    #-------------------
    # baseline settings
    #-------------------
    parser.add_argument("--baseline", type=str,   default="rollout")
    parser.add_argument("--bl_alpha", type=float, default=0.05)
    parser.add_argument("--beta",     type=float, default=0.8)
    
    #------------------
    # other parameters
    #------------------
    parser.add_argument("--vehicle_speed", type=float, default=41.0)
    parser.add_argument("--wait_time",     type=float, default=0.5)
    parser.add_argument("--time_horizon",  type=float, default=12.0)

    args = parser.parse_args()

    main(args)


--------------------------------------------------------------------------------
文件路径: /Users/dxk/Downloads/evrp-eps-main/eval.py
--------------------------------------------------------------------------------

import os
import torch
import json
import time
import argparse
import numpy as np
from tqdm import tqdm
from typing import Dict, Any
from utils.util import set_device, output_tour_to_csv, save_dataset, fix_seed
from generate_dataset import CIRPDataset
from models.am import AM4CIRP
from models.naive_models import NaiveModel
from models.state import visualize_routes as vis_routes
from models.state import save_route_info

def eval(dataset_path: str,
         eval_batch_size: int = 256,
         max_load_size: int = -1,
         model_type: str = "rl",
         model_path: str = None,
         model_dir: str = None,
         decode_type: str = "sampling",
         search_width: int = 12800,
         max_batch_size: int = 128,
         penalty_coef: float = 100,
         vehicle_speed: float = 41,
         wait_time: float = 0.5,
         time_horizon: float = 12,
         random_seed: int = 1234,
         gpu: int = -1,
         num_workers: int = 4,
         visualize_routes: bool = False,
         output_dir: str = None) -> Dict[str, Any]:
    #-----------------
    # set random seed
    #-----------------
    fix_seed(random_seed)
    
    #------------------------------
    # device settings (gpu or cpu)
    #------------------------------
    use_cuda, device = set_device(gpu)

    #---------
    # dataset
    #---------
    dataset = CIRPDataset().load_from_pkl(dataset_path, load_dataopts=False, max_load_size=max_load_size)
    dataloader = torch.utils.data.DataLoader(dataset,
                                             batch_size=eval_batch_size,
                                             shuffle=None,
                                             num_workers=num_workers)

    #-------
    # model
    #-------
    if model_type == "rl":
        # load a trained model
        if model_path is not None: 
            model_dir = os.path.split(model_path)[0]
        elif model_dir is not None:
            model_path = f"{model_dir}/model_bestepoch.pth"
        else:
            assert False, "specify the one from model_path and model_dir :("

        params = argparse.ArgumentParser()
        with open(f"{model_dir}/cmd_args.dat", "r") as f:
            params.__dict__ = json.load(f)
        model = AM4CIRP(loc_dim=params.loc_dim,
                        depot_dim=params.depot_dim,
                        vehicle_dim=params.vehicle_dim,
                        emb_dim=params.emb_dim,
                        num_heads=params.num_heads,
                        num_enc_layers=params.num_enc_layers,
                        dropout=params.dropout,
                        device=device)
        model.load_state_dict(torch.load(model_path))
        if use_cuda:
            model.to(device)
    elif model_type in ["naive_greedy", "naive_random", "wo_move"]:
        model = NaiveModel(model_type, device)
    else:
        raise TypeError("Invalid model_type!")

    #------------
    # evaluation
    #------------
    actual_tour_length_list = []
    tour_length_list = []
    down_list = []
    num_down_list = []
    calc_time_list = []
    model.eval()
    for batch_id, batch in enumerate(tqdm(dataloader)):
        start_time = time.perf_counter()
        
        if use_cuda:
            batch = {key: value.to(device) for key, value in batch.items()}
        # add options
        batch.update({
            "time_horizon": time_horizon,
            "vehicle_speed": vehicle_speed,
            "wait_time": wait_time
        })

        # output tours
        if model_type == "rl":
            if decode_type == "greedy":
                with torch.inference_mode():
                    cost_dict, vehicle_ids, node_ids, mask = model.greedy_decode(batch)
            elif decode_type == "sampling":
                with torch.inference_mode():
                    cost_dict, vehicle_ids, node_ids, mask = model.sample_decode(batch, search_width, max_batch_size)
            else:
                NotImplementedError
        elif model_type == "naive_random":
            cost_dict, vehicle_ids, node_ids, mask = model.sample_decode(batch, search_width, max_batch_size)
        elif model_type in ["naive_greedy", "wo_move"]:
            cost_dict, vehicle_ids, node_ids, mask = model.decode(batch)
        else:
            NotImplementedError

        calc_time_list.append(time.perf_counter() - start_time)
        tour_length_list.append(cost_dict["tour_length"])
        down_list.append(cost_dict["penalty"])
        num_down_list.append(cost_dict["penalty"] * batch["loc_coords"].size(1))
        actual_tour_length_list.append(cost_dict["tour_length"] * batch["grid_scale"].squeeze(-1))
        
        #---------------
        # visualization
        #---------------
        if visualize_routes:
            os.makedirs(output_dir, exist_ok=True)
            vis_routes(vehicle_ids, node_ids, batch, f"{output_dir}/batch{batch_id}", device)
            save_route_info(batch, vehicle_ids, node_ids, mask, f"{output_dir}/batch{batch_id}")

    #------------------
    # calculation time
    #------------------
    avg_calc_time = np.mean(calc_time_list)
    std_calc_time = np.std(calc_time_list)
    total_calc_time = np.sum(calc_time_list)
    
    #-----------------
    # objective value
    #-----------------
    tour_length = torch.cat(tour_length_list, dim=0) # [eval_size]
    down = torch.cat(down_list, dim=0) # [eval_size]
    all_costs = tour_length + penalty_coef * down # [eval_size]
    avg_obj = torch.mean(all_costs).cpu().item()
    std_obj = torch.std(all_costs, unbiased=False).cpu().item()
    avg_tour_length = torch.mean(tour_length).cpu().item()
    std_tour_length = torch.std(tour_length, unbiased=False).cpu().item()
    avg_down = torch.mean(down).cpu().item()
    std_down = torch.std(down, unbiased=False).cpu().item()
    num_down = torch.cat(num_down_list, dim=0)
    avg_num_down = torch.mean(num_down).cpu().item()
    std_num_down = torch.std(num_down, unbiased=False).cpu().item()
    actual_tour_length = torch.cat(actual_tour_length_list, dim=0)
    avg_actual_tour_length = torch.mean(actual_tour_length).cpu().item()
    std_actual_tour_length = torch.std(actual_tour_length, unbiased=False).cpu().item()

    summary = {
        "avg_calc_time": avg_calc_time,
        "std_calc_time": std_calc_time,
        "avg_obj": avg_obj,
        "std_obj": std_obj,
        "avg_tour_length": avg_tour_length,
        "std_tour_length": std_tour_length,
        "avg_down": avg_down,
        "std_down": std_down,
        "total_calc_time": total_calc_time,
        "avg_actual_tour_length": avg_actual_tour_length,
        "std_actual_tour_length": std_actual_tour_length,
        "avg_num_down": avg_num_down,
        "std_num_down": std_num_down
    }

    # save log
    if output_dir is not None:
        os.makedirs(output_dir, exist_ok=True)
        log_fname = f"{output_dir}/summary.json"
        with open(log_fname, "w") as f:
            json.dump(summary, f)

    return summary

if __name__ == "__main__":
    import datetime
    import argparse
    now = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
    parser = argparse.ArgumentParser()
    # general settings
    parser.add_argument("--random_seed",      type=int, default=1234)
    parser.add_argument("--gpu",              type=int, default=-1)
    parser.add_argument("--num_workers",      type=int, default=4)
    parser.add_argument("--visualize_routes", action="store_true")
    parser.add_argument("--output_dir",       type=str, default=f"results/results_{now}")
    # dataset settings
    parser.add_argument("--dataset_path",    type=str, required=True)
    parser.add_argument("--eval_batch_size", type=int, default=1)
    parser.add_argument("--max_load_size",   type=int, default=-1)
    # model settings
    parser.add_argument("--model_type",     type=str, default="rl")
    parser.add_argument("--model_path",     type=str, default=None)
    parser.add_argument("--model_dir",      type=str, default=None)
    parser.add_argument("--decode_type",    type=str, default="sampling")
    parser.add_argument("--search_width",   type=int, default=12800)
    parser.add_argument("--max_batch_size", type=int, default=12800)
    parser.add_argument("--penalty_coef",   type=float, default=100)
    # other parameters
    parser.add_argument("--vehicle_speed", type=float, default=41.0)
    parser.add_argument("--wait_time",     type=float, default=0.5)
    parser.add_argument("--time_horizon",  type=float, default=12.0)
    args = parser.parse_args()

    # prepare a directory
    if args.visualize_routes:
        os.makedirs(args.output_dir, exist_ok=True)

    eval(dataset_path=args.dataset_path,
         eval_batch_size=args.eval_batch_size,
         max_load_size=args.max_load_size,
         model_type=args.model_type,
         model_path=args.model_path,
         model_dir=args.model_dir,
         decode_type=args.decode_type,
         search_width=args.search_width,
         max_batch_size=args.max_batch_size,
         penalty_coef=args.penalty_coef,
         vehicle_speed=args.vehicle_speed,
         wait_time=args.wait_time,
         time_horizon=args.time_horizon,
         random_seed=args.random_seed,
         gpu=args.gpu,
         num_workers=args.num_workers,
         visualize_routes=args.visualize_routes,
         output_dir=args.output_dir)


--------------------------------------------------------------------------------
文件路径: /Users/dxk/Downloads/evrp-eps-main/utils/util.py
--------------------------------------------------------------------------------

import torch
import torch.backends.cudnn as cudnn
import os
import pickle
import numpy as np
import pandas as pd
import random

def fix_seed(seed):
    # random
    random.seed(seed)
    # numpy
    np.random.seed(seed)
    # pytorch
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

def set_device(gpu):
    """
    Parameters
    ----------
    gpu: int 
        Used GPU No. gpu=-1 indicates using cpu

    Returns
    -------
    use_cuda: bool
        whether a gpu is used or not
    device: str
        device name
    """
    if gpu >= 0:
        assert torch.cuda.is_available(), "There is no available GPU."
        torch.cuda.set_device(gpu)
        device = f"cuda:{gpu}"
        use_cuda = True
        cudnn.benchmark = True
        print(f'selected device: GPU #{gpu}')
    else:
        device = "cpu"
        use_cuda = False
        print(f'selected device: CPU')
    return use_cuda, device

def check_extension(filename):
    if os.path.splitext(filename)[1] != ".pkl":
        return filename + ".pkl"
    return filename

def save_dataset(dataset, filename):
    filedir = os.path.split(filename)[0]
    print(f"saving a dataset to {filename}...", end="", flush=True)
    if not os.path.isdir(filedir):
        os.makedirs(filedir)
    with open(check_extension(filename), 'wb') as f:
        pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)
    print("done")

def load_dataset(filename):
    with open(check_extension(filename), 'rb') as f:
        return pickle.load(f)

def output_tour_to_csv(input, tours, output_dir):
    """
    Parameters
    ----------
    input: dict of torch.tensor
    tours: 3d list [batch_size x num_vehicles x num_steps_of_the_vehicles]
        tour of each vehicle
    output_dir: str
    """
    batch = 0
    tours = tours[batch]
    num_vehicles = len(tours)

    # add initial position to tour list
    initial_position = input["vehicle_initial_position_id"][batch]
    for i in range(num_vehicles):
        tours[i].insert(0, (initial_position[i].item(), 0.0, 0.0))

    # generate multi_index
    info_list = ["tour", "travel_time (h)", "charge_time (h)"]
    vehicle_id = []
    info_name = []
    for i in range(num_vehicles):
        for info in info_list:
            vehicle_id.append(str(i))
            info_name.append(info)
    df_ind = pd.DataFrame({"vehicle_id": vehicle_id, "info": info_name})
    multi_index = pd.MultiIndex.from_frame(df_ind)

    # generate pandas framework
    max_steps = np.max([len(tours[i]) for i in range(num_vehicles)])
    data = {}; data_w_time = {}
    for i in range(max_steps):
        step = str(i)
        data[step] = []; data_w_time[step] = []
        for j in range(num_vehicles):
            if i >= len(tours[j]):
                data[step].append(np.nan)
                for k in range(len(info_list)):
                    data_w_time[step].append(np.nan)
            else:
                data[step].append(tours[j][i][0])
                for k in range(len(info_list)):                    
                    data_w_time[step].append(tours[j][i][k])

    df_tour = pd.DataFrame(
        data,
        index = [str(i) for i in range(num_vehicles)]
    )
    df_tour.index.name = "vehicle_id"

    df_tour_w_time = pd.DataFrame(
        data_w_time,
        index=multi_index
    )

    # save csv files
    df_tour.to_csv(f"{output_dir}/tour.csv")
    df_tour_w_time.to_csv(f"{output_dir}/tour_w_time.csv")


--------------------------------------------------------------------------------
文件路径: /Users/dxk/Downloads/evrp-eps-main/models/baselines.py
--------------------------------------------------------------------------------

import torch
from torch.utils.data import DataLoader
import copy
from tqdm import tqdm
from scipy.stats import ttest_rel
from generate_dataset import CIRPDataset

class Baseline(object):
    """
    super class for baselines of policy gradient
    """
    def __init__(self, device):
        self.device = device

    def wrap_dataset(self, dataset):
        return dataset

    def unwrap_batch(self, batch):
        return batch, None

    def eval(self, x, c):
        raise NotImplementedError("Override this method")

    def get_learnable_parameters(self):
        return []

    def epoch_callback(self, model, epoch):
        pass

    def state_dict(self):
        return {}

    def load_state_dict(self, state_dict):
        pass


class NoBaseline(Baseline):
    def eval(self, x, c):
        return 0, 0  # No baseline, no loss


class ExponentialBaseline(Baseline):
    def __init__(self, beta, device=None):
        super().__init__(device)
        self.beta = beta
        self.v = None

    def eval(self, x, c):
        if self.v is None:
            v = c.mean()
        else:
            v = self.beta * self.v + (1. - self.beta) * c.mean()
        self.v = v.detach()  # Detach since we never want to backprop
        return self.v, 0  # No loss

    def state_dict(self):
        return {
            'v': self.v
        }

    def load_state_dict(self, state_dict):
        self.v = state_dict['v']


class RolloutBaseline(Baseline):
    def __init__(self, model, opts, args, epoch=0, device="cpu"):
        super().__init__(device)
        self.opts = opts
        self.num_greedy_samples = args.num_greedy_samples
        self.greedy_batch_size = args.greedy_batch_size
        self.wait_time = args.wait_time
        self.vehicle_speed = args.vehicle_speed
        self.time_horizon = args.time_horizon
        self.bl_alpha = args.bl_alpha
        self._update_model(model, epoch)

    def epoch_callback(self, model, epoch):
        """
        update current baseline policy and evaluation dataset if the policy is improved.
        
        :param model: current training policy
        :param epoch: current epoch
        """
        print("evaluating current policy on evaluation dataset")
        candidate_vals = self.rollout(model, self.dataset, self.opts).cpu().numpy() # [test_size]
        candidate_mean = candidate_vals.mean() # [1]

        print("Epoch {} candidate mean {}, baseline epoch {} mean {}, difference {}".format(
            epoch, candidate_mean, self.epoch, self.mean, candidate_mean - self.mean))
        
        # if the policy is improved
        if candidate_mean - self.mean < 0:
            # Calc p value
            t, p = ttest_rel(candidate_vals, self.bl_vals)

            p_val = p / 2  # one-sided
            assert t < 0, "T-statistic should be negative"
            print("p-value: {}".format(p_val))
            if p_val < self.bl_alpha:
                print('Update baseline')
                self._update_model(model, epoch)

    def rollout(self, model, dataset, opts):
        """
        compute cost with greedy decoding
        
        :param model: current training policy or baseline policy
        :param dataset: evaluation dataset for comparing current policy with baseline one
        :param opts: parsed arguments
        :return: cost of each batch [val_size]
        """
        model.eval()
        def eval_model_bat(bat):
            with torch.no_grad():
                bat = {key: value.to(self.device) for key, value in bat.items()}
                bat.update({
                    "time_horizon": self.time_horizon,
                    "vehicle_speed": self.vehicle_speed,
                    "wait_time": self.wait_time
                })
                cost, _ = model(bat, "greedy") # [batch_size x 1] 
            return cost.data.cpu()

        return torch.cat([
            eval_model_bat(bat)
            for bat in tqdm(DataLoader(dataset, batch_size=self.greedy_batch_size))
        ], 0)

    def eval(self, x, c=None):
        """
        compute cost with greedy decoding. note:self.decode_type is set to greedy here.
        
        :param x: coordinates of points [batch_size x seq_length x node_dim]
        :retrun v: baseline (value) obtained from baseline policy
        """
        # Use volatile mode for efficient inference (single batch so we do not use rollout function)
        with torch.no_grad():
            v, _ = self.model(x, "greedy") # greedy decoding
        # There is no loss
        return v, 0
    
    def _update_model(self, model, epoch):
        """
        update baseline policy & evaluation dataset only when current policy is stronger than baseline one.
        
        :param model: current policy 
        :param epoch: current epoch
        """
        random_seed = self.opts.random_seed + sum(self.opts.num_samples) + 1 + epoch*self.num_greedy_samples
        # replace baseline policy with current training policy
        self.model = copy.deepcopy(model)
        
        # update dataset for comparing current policy with the baseline policy
        self.dataset = CIRPDataset().generate(num_samples=self.num_greedy_samples,
                                              num_locs=self.opts.num_locs,
                                              num_depots=self.opts.num_depots,
                                              num_vehicles=self.opts.num_vehicles,
                                              vehicle_cap=self.opts.vehicle_cap,
                                              vehicle_discharge_rate=self.opts.vehicle_discharge_rate,
                                              depot_discharge_rate=self.opts.depot_discharge_rate,
                                              discharge_lim_ratio=self.opts.discharge_lim_ratio,
                                              cap_ratio=self.opts.cap_ratio,
                                              grid_scale=self.opts.grid_scale,
                                              random_seed=random_seed)

        # compute cost of updated baseline policy with greedy decoding, and store it
        self.bl_vals = self.rollout(self.model, self.dataset, self.opts).cpu().numpy() # [test_size]
        self.mean = self.bl_vals.mean() # scalar: [1]
        self.epoch = epoch

    def state_dict(self):
        return {
            'model': self.model,
            'dataset': self.dataset,
            'epoch': self.epoch
        }


--------------------------------------------------------------------------------
文件路径: /Users/dxk/Downloads/evrp-eps-main/models/am.py
--------------------------------------------------------------------------------

import torch
import torch.nn as nn
import torch.nn.functional as F
from models.am_encoder import AMEncoder
from models.am_decoder import AMDecoder
from models.state import CIRPState

PENALTY_COEF = 100

class AM4CIRP(nn.Module):
    def __init__(self,
                 loc_dim: int,
                 depot_dim: int,
                 vehicle_dim: int,
                 emb_dim: int,
                 num_heads: int,
                 num_enc_layers: int,
                 dropout: float = 0.0,
                 device: str = "cpu"):
        super().__init__()
        self.device = device
        self.encoder = AMEncoder(loc_dim, depot_dim, vehicle_dim, emb_dim, num_heads, num_enc_layers, dropout)
        self.decoder = AMDecoder(emb_dim)

    def forward(self,
                input: dict,
                decode_type: str, 
                fname: str = None):
        """
        Parameters
        ----------
        input:
        decode_type: str
        output_tours: bool
        Returns
        -------
        rewards: dict
            tour_length: torch.tensor [batch_size]
            penalty: torch.tensor [batch_size]
        tour_logprobs: torch.tensor [batch_size]
        tours: list of list of list [batch_size x num_vehicles x num_vehicle_steps]
        """
        #-------------
        # action loop
        #-------------
        prob_list = []; tour_list = []; vehicle_list = []; skip_list = []
        state = CIRPState(input, self.device, fname)
        while not state.all_finished():
            loc_feats, depot_feats, vehicle_feats = state.get_inputs()
            mask = state.get_mask()
            # encoding
            node_context, vehicle_context = self.encoder(loc_feats, depot_feats, vehicle_feats)
            # decoding
            selected_vehicle_id = state.get_selected_vehicle_id()
            vehicle_context = torch.gather(vehicle_context, 1, selected_vehicle_id[:, None, None].expand(state.batch_size, 1, vehicle_context.size(-1)))
            probs, selected = self.decoder(node_context, vehicle_context, mask, decode_type)
            # store results
            prob_list.append(probs)
            tour_list.append(selected[:, None])
            vehicle_list.append(state.next_vehicle_id[:, None])
            skip_list.append(state.skip[:, None])
            # update state
            state.update(selected)
        #---------
        # rewards
        #---------
        # penalty_coef = PENALTY_COEF # input["time_horizon"] * input["vehicle_speed"] * state.num_vehicles * 10
        reward_dict = state.get_rewards()
        rewards = reward_dict["tour_length"] + PENALTY_COEF * reward_dict["penalty"] # [batach_size]
        
        # log probabilities
        prob_list  = torch.stack(prob_list, 1) # [batch_size x num_steps x num_nodes]
        tour_list  = torch.stack(tour_list, 1) # [batch_size x num_steps]
        tour_probs = torch.gather(prob_list, dim=2, index=tour_list).squeeze(-1) # [batch_size x num_steps]
        skip_list  = torch.stack(skip_list, 1).squeeze(-1) # [batch_size x num_steps]
        tour_logprobs = (torch.log(tour_probs + 1e-9) * ~skip_list).sum(-1) # [batch_size]
        tour_logprobs[(tour_logprobs < -1000).detach()] = 0.0 # for numerical stability
        
        # tour list for visualization TODO:
        if fname is not None:
            state.output_batt_history()
            state.output_gif()
            vehicle_list = torch.stack(vehicle_list, 1) # [batch_size x num_steps]
            skip_list = torch.stack(skip_list, 1) # [batch_size x num_steps]
            batch_size = state.batch_size
            num_steps  = skip_list.size(-1)
            tours = [[[] for _ in range(state.num_vehicles)] for __ in range(batch_size)]
            for batch in range(batch_size):
                for step in range(num_steps):
                    if not skip_list[batch, step]:
                        tours[batch][vehicle_list[batch, step]].append((tour_list[batch, step].item()))
            return rewards, tour_logprobs, reward_dict, tours
        else:
            return rewards, tour_logprobs
            
    def _rollout(self, 
                 input: dict,
                 decode_type: str, 
                 fname: str = None):
        """
        Parameters
        ----------
        input: dict
        decode_type: str
        fname: str
        
        Returns
        -------
        state: CIRPState
        prob_list: list
        tour_list: list
        vehicle_list: list
        skip_list: list
        """
        prob_list = []; tour_list = []; vehicle_list = []; skip_list = []
        state = CIRPState(input, self.device, fname)
        while not state.all_finished():
            loc_feats, depot_feats, vehicle_feats = state.get_inputs()
            mask = state.get_mask()
            # encoding
            node_context, vehicle_context = self.encoder(loc_feats, depot_feats, vehicle_feats)
            # decoding
            selected_vehicle_id = state.get_selected_vehicle_id()
            vehicle_context = torch.gather(vehicle_context, 1, selected_vehicle_id[:, None, None].expand(state.batch_size, 1, vehicle_context.size(-1)))
            probs, selected = self.decoder(node_context, vehicle_context, mask, decode_type)
            # store results
            prob_list.append(probs)
            tour_list.append(selected[:, None])
            vehicle_list.append(state.next_vehicle_id[:, None])
            skip_list.append(state.skip[:, None])
            # update state
            state.update(selected)
        return state, prob_list, tour_list, vehicle_list, skip_list
    
    def greedy_decode(self,
                      inputs: dict):
        state, prob_list, tour_list, vehicle_list, skip_list = self._rollout(inputs, "greedy")
        cost_dict = state.get_rewards()
        vehicle_ids = torch.cat(vehicle_list, -1)
        node_ids = torch.cat(tour_list, -1)
        masks = torch.cat(skip_list, -1)
        return cost_dict, vehicle_ids, node_ids, masks
    
    def replicate_batch(self,
                        inputs: dict,
                        num_replicas: int):
        """
        Replicates inputs for sampling/beam-search decoding
        
        Parameters
        ----------
        inputs: dict of torch.Tensor [batch_size x ...]
        num_replicas: int
        
        Returns
        -------
        replicated_inputs: dict of torch.Tensor [(num_replicas * batch_size) x ...]
        """
        return {
            k: v.unsqueeze(0).expand(num_replicas, *v.size()).reshape(-1, *v.size()[1:]) 
            if k not in ["time_horizon", "vehicle_speed", "wait_time"] else v
            for k, v in inputs.items()
        }

    def sample_decode(self, 
                      inputs: dict,
                      search_width: int,
                      max_batch_size: int = 1028):
        """
        Parameters
        ----------
        inputs: dict of torch.Tensor [batch_size x ...]
        search_width: int
        
        Returns
        -------
        min_cost: torch.Tensor [batch_size]
        vehicle_ids: torch.Tensor [batch_size x max_steps]
        node_ids: torch.Tensor [batch_size x max_steps]
        masks: torch.Tensor [batch_size x max_steps]
        """
        batch_size = len(inputs["loc_coords"])    
        if search_width * batch_size > max_batch_size:
            assert (max_batch_size % batch_size) == 0
            assert ((search_width * batch_size) % max_batch_size) == 0
            rep_batch = max_batch_size // batch_size
            num_itr = (search_width * batch_size) // max_batch_size
        else:
            rep_batch = search_width
            num_itr = 1
        penalty_coef = PENALTY_COEF
        rep_inputs = self.replicate_batch(inputs, rep_batch)
        node_id_list = []; vehicle_id_list = []; mask_list = []
        tour_length_list = []; penalty_list = []
        max_steps = 0
        for itr in range(num_itr):
            state, prob_list, tour_list, vehicle_list, skip_list = self._rollout(rep_inputs, "sampling")
            node_id_list.append(torch.stack(tour_list, 1).view(rep_batch, batch_size, -1))       # [rep_batch x batch_size x num_steps]    
            vehicle_id_list.append(torch.stack(vehicle_list, 1).view(rep_batch, batch_size, -1)) # [rep_batch x batch_size x num_steps]
            mask_list.append(torch.stack(skip_list, 1).view(rep_batch, batch_size, -1))          # [rep_batch x batch_size x num_steps]
            cost_dict = state.get_rewards()
            tour_length_list.append(cost_dict["tour_length"].view(rep_batch, batch_size)) # [rep_batch x batch_size]
            penalty_list.append(cost_dict["penalty"].view(rep_batch, batch_size)) # [rep_batch x batch_size]
            max_steps = max(max_steps, len(tour_list))
        # padding
        node_id_list = torch.cat([F.pad(node_ids, (0, max_steps - node_ids.size(-1)), "constant", 0) for node_ids in node_id_list], 0) # [search_width x batch_size x max_steps]
        vehicle_id_list = torch.cat([F.pad(vehicle_ids, (0, max_steps - vehicle_ids.size(-1)), "constant", 0) for vehicle_ids in vehicle_id_list], 0) # [search_width x batch_size x max_steps]
        mask_list = torch.cat([F.pad(masks, (0, max_steps - masks.size(-1)), "constant", True) for masks in mask_list], 0) # [search_width x batch_size x max_steps]
        tour_length_list = torch.cat(tour_length_list, 0) # [search_width x batch_size]
        penalty_list = torch.cat(penalty_list, 0) # [search_width x batch_size]
        cost_list = tour_length_list + penalty_coef * penalty_list # [search_width x batch_size]
        
        # extract a sample that has minimum cost
        min_cost, min_cost_idx = cost_list.min(0) # [1 x batch_size]
        min_cost_idx = min_cost_idx.reshape(1, batch_size)
        min_tour_length = tour_length_list.gather(0, min_cost_idx).squeeze(0) # [batch_size]
        min_penalty = penalty_list.gather(0, min_cost_idx).squeeze(0) # [batch_size]
        min_cost_idx = min_cost_idx.unsqueeze(-1).expand(1, batch_size, max_steps) # [1 x batch_size x max_steps]
        node_ids    = node_id_list.gather(0, min_cost_idx).squeeze(0)    # [batch_size x max_steps]
        vehicle_ids = vehicle_id_list.gather(0, min_cost_idx).squeeze(0) # [batch_size x max_steps]
        masks       = mask_list.gather(0, min_cost_idx).squeeze(0)    # [batch_size x max_steps]
        
        return {"tour_length": min_tour_length, "penalty": min_penalty}, vehicle_ids, node_ids, masks


--------------------------------------------------------------------------------
文件路径: /Users/dxk/Downloads/evrp-eps-main/models/am_decoder.py
--------------------------------------------------------------------------------

import torch
import torch.nn as nn
import math

class AMDecoder(nn.Module):
    def __init__(self, emb_dim):
        super().__init__()
        self.w_q = nn.Parameter(torch.Tensor(emb_dim, emb_dim))
        self.w_k = nn.Parameter(torch.Tensor(emb_dim, emb_dim))
        self.norm_factor = 1. / math.sqrt(emb_dim)
        self.tanh_clipping = 10.
        self.reset_paramters()

    def reset_paramters(self):
        for param in self.parameters():
            stdv = 1. / math.sqrt(param.size(-1))
            param.data.uniform_(-stdv, stdv)

    def forward(self, node_context, agent_context, mask, decode_type):
        """
        Paramters
        ---------
        node_context: torch.tensor [batch_size x num_nodes x emb_dim]
            context of nodes obtained from the node-encoder
        agent_context: torch.tensor [batch_size x num_agents x emb_dim]
            context of agents obtained from the agent-encoder
        mask: torch.tensor [batch_size x num_nodes]
            mask that removes infeasible nodes (0: infeasible, 1: feasible)

        Returns
        -------
        probs: torch.tensor [batch_size x num_nodes]
            probabilities of visiting nodes 
        next_node_id: torch.tensor [batch_size]
            id of a node visited in the next
        """
        query  = torch.matmul(agent_context, self.w_q) # [batch_size x 1 x emb_dim]
        key    = torch.matmul(node_context, self.w_k)  # [batch_size x num_nodes x emb_dim]
        logits = self.norm_factor * torch.matmul(query, key.transpose(-1, -2)).squeeze(1)  # [batch_size x 1 x num_nodes] -> [batch_size x num_nodes]
        logits = torch.tanh(logits) * self.tanh_clipping
        # masking
        logits[mask < 1] = -math.inf
        # get probs and determine nex node
        probs = torch.softmax(logits, dim=-1)
        if probs.isnan().any():
            batch_size = node_context.size(0)
            for i in range(batch_size):
                if probs[i].isnan().any():
                    print(f"batch: {i}, prob: {probs[i]}, h_node: {logits[i]}, mask: {mask[i]}")
            assert False
        # print(probs); import time; time.sleep(10)
        next_node_id = self.select_node(probs, mask, decode_type)
        return probs, next_node_id
    
    def select_node(self, probs, mask, decode_type):
        """
        Paramters
        ---------
        probs: torch.tensor [batch_size x num_nodes]
        mask: torch.tensor [batch_size x num_nodes]
        decode_type: str
            decoding type {sampling, greedy}

        Returns
        --------
        selected: torch.tensor [batch_size]
            id of a node visited in the next
        """
        assert (probs == probs).all(), "Probs should not contain any nans"

        if decode_type == "sampling":
            selected = probs.multinomial(1).squeeze(1)
            # check if sampling went OK, can go wrong due to bug on GPU:
            #   points with zero probability are sampled occasionally
            # see https://discuss.pytorch.org/t/bad-behavior-of-multinomial-function/10232
            while (mask.gather(1, selected.unsqueeze(-1)) == 0).data.any():
                print('Sampled bad values, resampling!')
                selected = probs.multinomial(1).squeeze(1)
        elif decode_type == "greedy":
            _, selected = probs.max(1)
            assert not (mask.gather(1, selected.unsqueeze(-1)) == 0).data.any(), "Decode greedy: infeasible action has maximum probability"
        else:
            assert False, f"decode type:{self.decode_type} is not supported."
        return selected


--------------------------------------------------------------------------------
文件路径: /Users/dxk/Downloads/evrp-eps-main/models/naive_models.py
--------------------------------------------------------------------------------

import torch
import torch.nn as nn
import torch.nn.functional as F
from models.state import CIRPState

PENALTY_COEF = 100

class NaiveModel(nn.Module):
    def __init__(self,
                 model_type = "naive_greedy",
                 device: str = "cpu"):
        super().__init__()
        self.device = device
        self.model_type = model_type

    def decode(self,
               inputs: dict):
        """
        Parameters
        ----------

        Returns
        -------

        """
        state, tour_list, vehicle_list, skip_list = self._rollout(inputs)
        cost_dict = state.get_rewards()
        vehicle_ids = torch.cat(vehicle_list, -1) 
        node_ids    = torch.cat(tour_list, -1)
        pad_masks   = torch.cat(skip_list, -1)
        return cost_dict, vehicle_ids, node_ids, pad_masks

    def _rollout(self, 
                 input: dict, 
                 fname: str = None):
        """
        Parameters
        ----------
        input: dict
        decode_type: str
        fname: str
        
        Returns
        -------
        state: CIRPState
        prob_list: list
        tour_list: list
        vehicle_list: list
        skip_list: list
        """
        tour_list = []; vehicle_list = []; skip_list = []
        state = CIRPState(input, self.device, fname)
        while not state.all_finished():
            loc_feats, depot_feats, vehicle_feats = state.get_inputs()
            node_mask = state.get_mask() # [batch_size x num_nodes]
            # decoding
            selected_vehicle_id = state.get_selected_vehicle_id()
            if self.model_type == "naive_greedy":
                selected_node_ids = self.greedy_decode(loc_feats, depot_feats, vehicle_feats, selected_vehicle_id, node_mask) # [batch_size]
            elif self.model_type == "naive_random":
                selected_node_ids = self.random_decode(node_mask) # [batch_size]
            elif self.model_type == "wo_move":
                selected_node_ids = self.without_move(state.get_curr_nodes())
            else:
                NotImplementedError
            # store results
            tour_list.append(selected_node_ids[:, None])
            vehicle_list.append(state.next_vehicle_id[:, None])
            skip_list.append(state.skip[:, None])
            # update state
            state.update(selected_node_ids) # [batch_size]
        return state, tour_list, vehicle_list, skip_list
    
    def greedy_decode(self,
                      loc_feats,
                      depot_feats,
                      vehicle_feats,
                      selected_vehicle_id,
                      node_mask):
        """
        Parameters
        ----------
        
        Returns
        -------
        selected_node_ids: torch.LongTensor [batch_size]
        """
        num_locs = loc_feats.size(1)
        # if at least one visitable location exists, select the location whose battery is minimum as the next destination
        loc_mask = node_mask[:, :num_locs] # [batch_size, num_locs]
        loc_batch = loc_mask.sum(-1) > 0 # [batch_size]
        loc_batt = loc_feats[:, :, -1] # [batch_size, num_locs]
        loc_batt_min_idx = (loc_batt + ~loc_mask * 1e+9).min(-1)[1] # remove unvisitable locations by adding a large value [batch_size]
        selected_node_ids = loc_batt_min_idx * loc_batch
        
        # if no visitable location exists, select the nearest depot to the current position as the next destination
        depot_batch = ~loc_batch
        batch_size = depot_batch.size(0)
        vehicle_corrds = vehicle_feats[:, :, 1:3] # [batch_size, num_vehicles, coord_dim]
        curr_coords = vehicle_corrds.gather(1, selected_vehicle_id[:, None, None].expand(batch_size, 1, vehicle_corrds.size(-1))) # [batch_size, 1, coord_dim]
        depot_coords = depot_feats[:, :, :2] # [batch_size, num_depots, coord_dim]
        nearest_depot_idx = torch.min(torch.linalg.norm(curr_coords - depot_coords, dim=-1), -1)[1] # [batch_size]
        selected_node_ids += (nearest_depot_idx + num_locs) * depot_batch # [batch_size]

        return selected_node_ids
    
    def random_decode(self,
                      node_mask):
        """
        Parameters
        ----------
        node_mask: torch.BoolTensor [batch_size, num_nodes]
        """
        num_avail_nodes = node_mask.sum(-1) # [batch_size]
        probs = (1. / num_avail_nodes).unsqueeze(-1) * node_mask
        selected = probs.multinomial(1).squeeze(1)
        # check if sampling went OK, can go wrong due to bug on GPU:
        #   points with zero probability are sampled occasionally
        # see https://discuss.pytorch.org/t/bad-behavior-of-multinomial-function/10232
        while (node_mask.gather(1, selected.unsqueeze(-1)) == 0).data.any():
            print('Sampled bad values, resampling!')
            selected = probs.multinomial(1).squeeze(1)

        return selected

    def without_move(self,
                     curr_nodes):
        """
        Parameters
        ----------
        
        """
        return curr_nodes
    
    def replicate_batch(self,
                        inputs: dict,
                        num_replicas: int):
        """
        Replicates inputs for sampling/beam-search decoding
        
        Parameters
        ----------
        inputs: dict of torch.Tensor [batch_size x ...]
        num_replicas: int
        
        Returns
        -------
        replicated_inputs: dict of torch.Tensor [(num_replicas * batch_size) x ...]
        """
        return {
            k: v.unsqueeze(0).expand(num_replicas, *v.size()).reshape(-1, *v.size()[1:]) 
            if k not in ["time_horizon", "vehicle_speed", "wait_time"] else v
            for k, v in inputs.items()
        }

    def sample_decode(self, 
                      inputs: dict,
                      search_width: int,
                      max_batch_size: int = 1028):
        """
        Parameters
        ----------
        inputs: dict of torch.Tensor [batch_size x ...]
        search_width: int
        
        Returns
        -------
        min_cost: torch.Tensor [batch_size]
        vehicle_ids: torch.Tensor [batch_size x max_steps]
        node_ids: torch.Tensor [batch_size x max_steps]
        masks: torch.Tensor [batch_size x max_steps]
        """
        batch_size = len(inputs["loc_coords"])    
        if search_width * batch_size > max_batch_size:
            assert (max_batch_size % batch_size) == 0
            assert ((search_width * batch_size) % max_batch_size) == 0
            rep_batch = max_batch_size // batch_size
            num_itr = (search_width * batch_size) // max_batch_size
        else:
            rep_batch = search_width
            num_itr = 1
        penalty_coef = PENALTY_COEF
        rep_inputs = self.replicate_batch(inputs, rep_batch)
        node_id_list = []; vehicle_id_list = []; mask_list = []
        tour_length_list = []; penalty_list = []
        max_steps = 0
        for itr in range(num_itr):
            state, tour_list, vehicle_list, skip_list = self._rollout(rep_inputs)
            node_id_list.append(torch.stack(tour_list, 1).view(rep_batch, batch_size, -1))       # [rep_batch x batch_size x num_steps]    
            vehicle_id_list.append(torch.stack(vehicle_list, 1).view(rep_batch, batch_size, -1)) # [rep_batch x batch_size x num_steps]
            mask_list.append(torch.stack(skip_list, 1).view(rep_batch, batch_size, -1))          # [rep_batch x batch_size x num_steps]
            cost_dict = state.get_rewards()
            tour_length_list.append(cost_dict["tour_length"].view(rep_batch, batch_size)) # [rep_batch x batch_size]
            penalty_list.append(cost_dict["penalty"].view(rep_batch, batch_size)) # [rep_batch x batch_size]
            max_steps = max(max_steps, len(tour_list))
        # padding
        node_id_list = torch.cat([F.pad(node_ids, (0, max_steps - node_ids.size(-1)), "constant", 0) for node_ids in node_id_list], 0) # [search_width x batch_size x max_steps]
        vehicle_id_list = torch.cat([F.pad(vehicle_ids, (0, max_steps - vehicle_ids.size(-1)), "constant", 0) for vehicle_ids in vehicle_id_list], 0) # [search_width x batch_size x max_steps]
        mask_list = torch.cat([F.pad(masks, (0, max_steps - masks.size(-1)), "constant", True) for masks in mask_list], 0) # [search_width x batch_size x max_steps]
        tour_length_list = torch.cat(tour_length_list, 0) # [search_width x batch_size]
        penalty_list = torch.cat(penalty_list, 0) # [search_width x batch_size]
        cost_list = tour_length_list + penalty_coef * penalty_list # [search_width x batch_size]
        
        # extract a sample that has minimum cost
        min_cost, min_cost_idx = cost_list.min(0) # [1 x batch_size]
        min_cost_idx = min_cost_idx.reshape(1, batch_size)
        min_tour_length = tour_length_list.gather(0, min_cost_idx).squeeze(0) # [batch_size]
        min_penalty = penalty_list.gather(0, min_cost_idx).squeeze(0) # [batch_size]
        min_cost_idx = min_cost_idx.unsqueeze(-1).expand(1, batch_size, max_steps) # [1 x batch_size x max_steps]
        node_ids    = node_id_list.gather(0, min_cost_idx).squeeze(0)    # [batch_size x max_steps]
        vehicle_ids = vehicle_id_list.gather(0, min_cost_idx).squeeze(0) # [batch_size x max_steps]
        masks       = mask_list.gather(0, min_cost_idx).squeeze(0)    # [batch_size x max_steps]
        
        return {"tour_length": min_tour_length, "penalty": min_penalty}, vehicle_ids, node_ids, masks


--------------------------------------------------------------------------------
文件路径: /Users/dxk/Downloads/evrp-eps-main/models/state.py
--------------------------------------------------------------------------------

import torch
import pickle
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import os
import math
import numpy as np
from matplotlib.offsetbox import OffsetImage, AnnotationBbox
from matplotlib import patches
import copy
import subprocess
from typing import Dict, List

DPI = 150
SMALL_VALUE = 1e-9
BIT_SMALL_VALUE = 1e-3
SAVE_PICTURE = False
SAVE_HISTORY = True
OUTPUT_INTERVAL = 0.01
FPS = 60
UNEQUAL_INTERVAL = False
COEF = 1.0
V_COEF = 1.0

#--------------------------
# when input is route_list
#--------------------------
def visualize_routes2(route_list: List[List[int]],
                      inputs: Dict[str, torch.tensor], 
                      fname: str, 
                      device: str) -> None:
    state = CIRPState(inputs, device, fname)
    count = [2 for _ in range(len(route_list))]
    while not state.all_finished():
        selected_vehicle_id = state.get_selected_vehicle_id()
        node_id = route_list[selected_vehicle_id][count[selected_vehicle_id]]
        node_ids = torch.LongTensor([node_id])
        state.update(node_ids)
        count[selected_vehicle_id] += 1
    
    if SAVE_PICTURE:
        state.output_gif()
    if SAVE_HISTORY:
        state.output_batt_history()

#-------------------------------------------------
# when input is the selected vehicle & node order
#-------------------------------------------------
def visualize_routes(vehicle_ids: torch.tensor, 
                     node_ids: torch.tensor, 
                     inputs: Dict[str, torch.tensor], 
                     fname: str, 
                     device: str):
    if vehicle_ids.dim() < 2: # if batch_size = 1
        vehicle_ids = vehicle_ids.unsqueeze(0).expand(1, node_ids.size(-1))
        node_ids = node_ids.unsqueeze(0).expand(1, node_ids.size(-1))
        
    state = CIRPState(inputs, device, fname)
    count = 0
    while not state.all_finished():
        assert (state.next_vehicle_id != vehicle_ids[:, count]).sum() == 0
        state.update(node_ids[:, count])
        count += 1
    
    if SAVE_PICTURE:
        state.output_gif()
    if SAVE_HISTORY:
        state.output_batt_history()

def save_route_info(inputs: Dict[str, torch.tensor], 
                    vehicle_ids: torch.tensor, 
                    node_ids: torch.tensor, 
                    mask: torch.tensor, 
                    output_dir: str) -> None:
    if vehicle_ids.dim() < 2: # if batch_size = 1
        vehicle_ids = vehicle_ids.unsqueeze(0).expand(1, node_ids.size(-1))
        node_ids = node_ids.unsqueeze(0).expand(1, node_ids.size(-1))
        mask = mask.unsqueeze(0).expand(1, mask.size(-1))
    sample = 0
    loc_coords = inputs["loc_coords"][sample].tolist()
    depot_coords = inputs["depot_coords"][sample].tolist()
    veh_init_pos_ids = inputs["vehicle_initial_position_id"][sample].tolist()

    ignored_depots = (inputs["depot_discharge_rate"][sample] < 10.0).tolist()
    for veh_init_pos_id in veh_init_pos_ids:
        ignored_depots[veh_init_pos_id - len(loc_coords)] = False

    vehicle_id = vehicle_ids[sample]
    node_id = node_ids[sample]
    mask = mask[sample]
    routes = [ [] for _ in range(torch.max(vehicle_id)+1)]
    assert len(vehicle_id) == len(node_id) and len(node_id) == len(mask)
    # add initial position
    for veh_id, veh_init_pos_id in enumerate(veh_init_pos_ids):
        routes[veh_id].append(veh_init_pos_id)
    # add subsequent positions
    for step, skip in enumerate(mask):
        if skip:
            break
        else:
            routes[vehicle_id[step]].append(node_id[step].item())
    route_info = {
        "loc_coords": loc_coords,
        "depot_coords": depot_coords,
        "ignored_depots": ignored_depots,
        "route": routes
    }
    os.makedirs(f"{output_dir}-sample{sample}", exist_ok=True)
    with open(f"{output_dir}-sample{sample}/route_info.pkl", "wb") as f:
        pickle.dump(route_info, f)

class CIRPState(object):
    def __init__(self,
                 input: dict,
                 device: str,
                 fname: str = None):
        #-----------
        # locations
        #-----------
        # static 
        self.loc_coords       = input["loc_coords"]         # [batch_size x num_locs x coord_dim]
        self.loc_cap          = input["loc_cap"]            # [batch_size x num_locs]
        self.loc_consump_rate = input["loc_consump_rate"]   # [batch_size x num_locs]
        # dynamic
        self.loc_curr_battery = input["loc_initial_battery"].clone() # [batch_size x num_locs]

        #--------
        # depots
        #--------
        # static
        self.depot_coords = input["depot_coords"] # [batch_size x num_depots x coord_dim]
        self.depot_discharge_rate = input["depot_discharge_rate"] # [batch_size x num_depots]
        # depots whose discharge rate is less than threshold
        self.th = 10.0
        self.small_depots = self.depot_discharge_rate < self.th # [batch_size x num_depots]
        
        #-------------------
        # locations & depot
        #-------------------
        self.coords = torch.cat((self.loc_coords, self.depot_coords), 1)

        #----------
        # vehicles
        #----------
        # TODO: speed should depend on edges, not vehicles
        # static
        self.vehicle_cap = input["vehicle_cap"].clone().detach()   # [batch_size x num_vehicles]
        self.vehicle_discharge_lim = input["vehicle_discharge_lim"].clone().detach() # [batch_size x num_vehicles]
        self.vehicle_discharge_rate = input["vehicle_discharge_rate"] # [batch_size x num_vehicles]
        # dynamic
        self.vehicle_position_id  = input["vehicle_initial_position_id"].clone() # node ids in which vehicles are [batch_size x num_vehicles]
        self.vehicle_curr_battery = input["vehicle_cap"].clone() # initialized with battery fully chareged [batch_size x num_vehicles]
        self.vehicle_unavail_time = torch.zeros(self.vehicle_cap.size(), dtype=torch.float, device=device) # [batch_size x num_vehicles]
        self.wait_vehicle = torch.full(self.vehicle_cap.size(), False, device=device) # [batch_size x num_vehicles] stores whether the vehicle is waiting or not
        self.phase_id = {"move": 0, "pre": 1, "charge": 2, "post": 3}
        self.phase_id_max = max(self.phase_id.values())
        self.vehicle_phase = torch.full(self.vehicle_cap.size(), self.phase_id["post"], dtype=torch.long, device=device) # [batch_size x num_vehicles] # 0 -> "move", 1 -> "charge"
        self.vehicle_consump_rate = input["vehicle_consump_rate"].clone()
        self.vehicle_position_id_prev  = input["vehicle_initial_position_id"].clone() # for visualization
        self.vehicle_move_time = torch.zeros(self.vehicle_cap.size(), dtype=torch.float, device=device)
        self.vehicle_pre_time  = torch.zeros(self.vehicle_cap.size(), dtype=torch.float, device=device)
        self.vehicle_work_time = torch.zeros(self.vehicle_cap.size(), dtype=torch.float, device=device)
        self.vehicle_post_time = torch.zeros(self.vehicle_cap.size(), dtype=torch.float, device=device)
        #-----------
        # paramters
        #-----------
        self.batch_size   = self.loc_coords.size(0)
        self.coord_dim    = self.loc_coords.size(-1)
        self.num_locs     = self.loc_coords.size(1)
        self.num_depots   = self.depot_coords.size(1)
        self.num_vehicles = self.vehicle_cap.size(1)
        self.num_nodes    = self.num_locs + self.num_depots
        self.wait_time    = torch.FloatTensor([input["wait_time"]]).to(device)
        self.time_horizon = torch.FloatTensor([input["time_horizon"]]).to(device)
        self.speed        = V_COEF * (torch.FloatTensor([input["vehicle_speed"]]).to(device) / input["grid_scale"]).squeeze(-1) # [batch_size x 1] -> [batch_size]
        self.max_cap      = torch.max(torch.tensor([torch.max(self.loc_cap).item(), torch.max(self.vehicle_cap).item()])).to(device) 
        self.device       = device
        self.loc_min_battery = 0.0 # TODO
        depot_prepare_time = 0.17 # 10 mins
        loc_prepare_time   = 0.5  # 30 mins
        self.pre_time_depot  = torch.FloatTensor([depot_prepare_time]).to(device)
        self.post_time_depot = torch.FloatTensor([depot_prepare_time]).to(device)
        self.post_time_loc   = torch.FloatTensor([loc_prepare_time]).to(device)
        self.pre_time_loc    = torch.FloatTensor([loc_prepare_time]).to(device)
        self.return_depot_within_time_horizon = False
        
        #-------
        # utils
        #-------
        self.loc_arange_idx     = torch.arange(self.num_locs).to(self.device).unsqueeze(0).expand(self.batch_size, -1)
        self.depot_arange_idx   = torch.arange(self.num_locs, self.num_nodes).to(self.device).unsqueeze(0).expand(self.batch_size, -1)
        self.node_arange_idx    = torch.arange(self.num_nodes).to(self.device).unsqueeze(0).expand(self.batch_size, -1)
        self.vehicle_arange_idx = torch.arange(self.num_vehicles).to(self.device).unsqueeze(0).expand(self.batch_size, -1)
        
        #----------------------
        # common dynamic state
        #----------------------
        self.next_vehicle_id = torch.zeros(self.batch_size, dtype=torch.long, device=device) # firstly allocate 0-th vehicles
        self.skip = torch.full((self.batch_size,), False, dtype=bool, device=device) # [batch_size]
        self.end  = torch.full((self.batch_size,), False, dtype=bool, device=device) # [batch_size]
        self.current_time = torch.zeros(self.batch_size, dtype=torch.float, device=device) # [bath_size]
        self.tour_length = torch.zeros(self.batch_size, dtype=torch.float, device=device) # [batch_size]
        self.penalty_empty_locs = torch.zeros(self.batch_size, dtype=torch.float, device=device) # [batch_size]
        next_vehicle_mask = torch.arange(self.num_vehicles).to(self.device).unsqueeze(0).expand(self.batch_size, -1).eq(self.next_vehicle_id.unsqueeze(-1)) # [batch_size x num_vehicles]
        self.mask = self.update_mask(self.vehicle_position_id[next_vehicle_mask], next_vehicle_mask)
        self.charge_queue = torch.zeros((self.batch_size, self.num_depots, self.num_vehicles), dtype=torch.long, device=device)

        #-------------------
        # for visualization
        #-------------------
        self.fname = fname
        self.episode_step = 0
        if fname is not None:
            self.vehicle_batt_history = [[[] for __ in range(self.num_vehicles)] for _ in range(self.batch_size)]
            self.loc_batt_history = [[[] for __ in range(self.num_locs)] for _ in range(self.batch_size)]
            self.time_history = [[] for _ in range(self.batch_size)]
            self.down_history = [[] for _ in range(self.batch_size)]
            # visualize initial state
            all_batch = torch.full((self.batch_size, ), True, device=self.device)
            self.visualize_state_batch(all_batch)

    def reset(self, input):
        self.__init__(input)

    def get_coordinates(self, node_id: torch.Tensor):
        """
        Paramters
        ---------
        node_id: torch.LongTensor [batch_size]

        Returns
        -------
        coords: torch.FloatTensor [batch_size x coord_dim]
        """
        return self.coords.gather(1, node_id[:, None, None].expand(self.batch_size, 1, self.coord_dim)).squeeze(1)
    
    def is_depot(self, node_id: torch.Tensor):
        """
        Paramters
        ---------
        node_id: torch.Tensor [batch_size]:
        """
        return node_id.ge(self.num_locs)

    def get_loc_mask(self, node_id: torch.Tensor):
        """
        Paramters
        ---------
        node_id: torch.Tensor [batch_size]:
        """
        return self.loc_arange_idx.eq(node_id.unsqueeze(-1))

    def get_depot_mask(self, node_id: torch.Tensor):
        """
        Paramters
        ---------
        node_id: torch.Tensor [batch_size]:
        """
        return self.depot_arange_idx.eq(node_id.unsqueeze(-1))
    
    def get_vehicle_mask(self, vehicle_id: torch.Tensor):
        """
        Paramters
        ---------
        vehicle_id: torch.Tensor [batch_size]:
        """
        return self.vehicle_arange_idx.eq(vehicle_id.unsqueeze(-1))

    def get_curr_nodes(self):
        return self.vehicle_position_id[self.get_vehicle_mask(self.next_vehicle_id)]

    def update(self,
               next_node_id: torch.Tensor):
        """
        Paramters
        ---------
        next_node_id: torch.LongTensor [batch_size]
            ids of nodes where the currently selected vehicles visit next
        """
        curr_vehicle_id = self.next_vehicle_id # [batch_size]
        curr_vehicle_mask = self.get_vehicle_mask(curr_vehicle_id) # [batch_size x num_vehicles]
        # assert (self.vehicle_phase[curr_vehicle_mask] == self.phase_id["post"]).sum() == self.batch_size, "all sected vehicles should be in post phase"

        #-------------------------------------------
        # update currrently selected vehicle's plan
        #-------------------------------------------
        # calculate travel distance & time of the currently selected vehicle
        curr_node_id = self.vehicle_position_id.gather(-1, curr_vehicle_id.unsqueeze(-1)).squeeze(-1) # [batch_size]
        curr_coords = self.get_coordinates(curr_node_id) # [batch_size x coord_dim]
        next_coords = self.get_coordinates(next_node_id) # [batch_size x coord_dim]
        travel_distance = COEF * torch.linalg.norm(curr_coords - next_coords, dim=-1) # [batch_size]
        travel_time = travel_distance / self.speed # [batch_size]

        # check waiting vehicles
        do_wait = (curr_node_id == next_node_id) & ~self.skip # [batch_size] wait: stay at the same place
        self.wait_vehicle.scatter_(-1, index=curr_vehicle_id.unsqueeze(-1), src=do_wait.unsqueeze(-1))

        # update the plan of the selected vehicles
        self.vehicle_unavail_time.scatter_(-1, curr_vehicle_id.unsqueeze(-1), travel_time.unsqueeze(-1))
        self.vehicle_position_id_prev.scatter_(-1, curr_vehicle_id.unsqueeze(-1), curr_node_id.unsqueeze(-1))
        self.vehicle_position_id.scatter_(-1, curr_vehicle_id.unsqueeze(-1), next_node_id.unsqueeze(-1))
        self.vehicle_phase.scatter_(-1, curr_vehicle_id.unsqueeze(-1), self.phase_id["move"])

        #---------------------------
        # estimate store phase time
        #---------------------------
        # moving 
        self.vehicle_move_time.scatter_(-1, curr_vehicle_id.unsqueeze(-1), travel_time.unsqueeze(-1)) # [batch_size x num_vehicles]
        
        # pre/post-operation time
        at_depot = self.is_depot(next_node_id).unsqueeze(-1)
        at_loc = ~at_depot
        curr_vehicle_at_loc = curr_vehicle_mask & at_loc
        curr_vehicle_at_depot = curr_vehicle_mask & at_depot
        self.vehicle_pre_time  += curr_vehicle_at_loc * self.pre_time_loc + curr_vehicle_at_depot * self.pre_time_depot
        self.vehicle_post_time += curr_vehicle_at_loc * self.post_time_loc + curr_vehicle_at_depot * self.post_time_depot
        
        # charge/supply time
        destination_loc_mask = self.get_loc_mask(next_node_id) # [batch_size x num_locs]
        #-------------------------------------
        # supplying time (visiting locations)
        #-------------------------------------
        unavail_depots = self.get_unavail_depots2(next_node_id).unsqueeze(-1).expand_as(self.depot_coords)
        depot_coords = self.depot_coords + 1e+6 * unavail_depots
        loc2depot_min = COEF * torch.linalg.norm(self.get_coordinates(next_node_id).unsqueeze(1) - depot_coords, dim=-1).min(-1)[0] # [batch_size] 
        discharge_lim = torch.maximum(loc2depot_min.unsqueeze(-1) * self.vehicle_consump_rate, self.vehicle_discharge_lim) # [batch_size x num_vehicles]
        veh_discharge_lim = (self.vehicle_curr_battery - (travel_distance.unsqueeze(-1) * self.vehicle_consump_rate) - discharge_lim).clamp(0.0)
        demand_on_arrival = torch.minimum(((self.loc_cap - (self.loc_curr_battery - self.loc_consump_rate * (travel_time.unsqueeze(-1) + self.pre_time_loc)).clamp(0.0)) * destination_loc_mask).sum(-1, keepdim=True), 
                                            veh_discharge_lim) # [batch_size x num_vehicles]
        # split supplying TODO: need clippling ?
        charge_time_tmp = demand_on_arrival / (self.vehicle_discharge_rate - (self.loc_consump_rate * destination_loc_mask).sum(-1, keepdim=True)) # [batch_sizee x num_vehicles]
        cannot_supplly_full = ((veh_discharge_lim - charge_time_tmp * self.vehicle_discharge_rate) < 0.0) # [batch_size x num_vehicles]
        next_vehicles_sd  = curr_vehicle_at_loc & cannot_supplly_full  # vehicles that do split-delivery [batch_size x num_vehicles]
        next_vehicles_nsd = curr_vehicle_at_loc & ~cannot_supplly_full # vehicles that do not split-delivery [batch_size x num_vehicles]
        charge_time = (charge_time_tmp * next_vehicles_nsd).sum(-1) # [batch_size]
        charge_time += ((veh_discharge_lim / self.vehicle_discharge_rate) * next_vehicles_sd).sum(-1) # [batch_size]
        #---------------------------------
        # charging time (visiting depots)
        #---------------------------------
        curr_depot_mask = self.get_depot_mask(next_node_id) # [batch_size x num_depots]
        charge_time += (((self.vehicle_cap - (self.vehicle_curr_battery - (travel_distance.unsqueeze(-1) * self.vehicle_consump_rate)).clamp(0.0)) / ((self.depot_discharge_rate * curr_depot_mask).sum(-1, keepdim=True) + SMALL_VALUE)) * curr_vehicle_at_depot).sum(-1) # charge time for split supplying (loc will not be fully [charged)
        #--------------------------------------------------------
        # update unavail_time (charge_time) of selected vehicles
        #--------------------------------------------------------
        self.vehicle_work_time += charge_time.clamp(0.0).unsqueeze(-1) * (curr_vehicle_mask & ~self.wait_vehicle) # [charging_batch_size]
        self.vehicle_work_time += self.wait_time * (curr_vehicle_mask & self.wait_vehicle) # waiting vehicles
        
        #----------------------------------------------------------------------
        # select a vehicle that we determine its plan while updating the state
        # (greddy approach: select a vehicle whose unavail_time is minimum)
        #----------------------------------------------------------------------
        # align the phase of the selected vehicles to "post"
        num_not_post = 1 # temporaly initial value
        while num_not_post > 0:
            vechicle_unavail_time_min, next_vehicle_id = self.vehicle_unavail_time.min(dim=-1) # [batch_size], [batch_size]
            next_vehicle_mask = self.get_vehicle_mask(next_vehicle_id) # [batch_size x num_vehicles]
            not_post_batch = (self.vehicle_phase[next_vehicle_mask] != self.phase_id["post"]) # [batch_size]
            num_not_post = (not_post_batch).sum()
            if num_not_post > 0:
                self.update_state(vechicle_unavail_time_min, self.vehicle_position_id[next_vehicle_mask], next_vehicle_id, next_vehicle_mask, not_post_batch, align_phase=True)
        # now, all the vehicle selected in all the batchs should be in charge phase
        # update the state at the time when the selected vehicles finish charging
        vechicle_unavail_time_min, next_vehicle_id = self.vehicle_unavail_time.min(dim=-1) # [batch_size], [batch_size]
        self.next_vehicle_id = next_vehicle_id
        next_vehicle_mask = self.get_vehicle_mask(next_vehicle_id) # [batch_size x num_vehicles]
        next_node_id = self.vehicle_position_id[next_vehicle_mask]
        all_batch = torch.full((self.batch_size, ), True, device=self.device)
        self.update_state(vechicle_unavail_time_min, next_node_id, next_vehicle_id, next_vehicle_mask, all_batch, align_phase=False)

        #-------------
        # update mask
        #-------------
        self.mask = self.update_mask(next_node_id, next_vehicle_mask)

        #--------------------------
        # validation check of mask
        #--------------------------
        all_zero = self.mask.sum(-1) == 0 # [batch_size]
        assert not all_zero.any(), "there is no node that the vehicle can visit!"

    def update_state(self, 
                     elapsed_time: torch.Tensor,
                     next_node_id: torch.Tensor,
                     next_vehicle_id: torch.Tensor, 
                     next_vehicle_mask: torch.Tensor, 
                     update_batch: torch.Tensor,
                     align_phase: bool):
        """
        Parameters
        ----------
        elapsed_time: torch.FloatTensor [batch_size]
        next_node_id: torch.LongTensor [batch_size]
        next_vehicle_id: torch.LongTensor [batch_size]
        next_vehicle_mask: torch.BoolTensor [batch_size x num_vehicles]
        update_batch: torch.BoolTensor [batch_size]
        align_phase: bool
        """
        #-------------------
        # clip elapsed_time
        #-------------------
        remaing_time = (self.time_horizon - self.current_time).clamp(0.0) # [batch_size]
        elapsed_time = torch.minimum(remaing_time, elapsed_time)
        
        #---------------------------------------------
        # moving vehicles (consuming vehicle battery)
        #---------------------------------------------
        moving_vehicles = (self.vehicle_phase == self.phase_id["move"]) & update_batch.unsqueeze(-1) # [batch_size x num_vehicles]
        moving_not_wait_vehicles = moving_vehicles & ~self.wait_vehicle # [batch_size x num_vehicles]
        self.vehicle_curr_battery -= self.vehicle_consump_rate * (self.speed * elapsed_time).unsqueeze(-1) * moving_not_wait_vehicles # Travel battery consumption
        # update total tour length
        # self.tour_length[update_batch] += moving_vehicles.sum(-1)[update_batch] * self.speed[update_batch] * elapsed_time[update_batch]
        self.tour_length += moving_vehicles.sum(-1) * self.speed * elapsed_time * update_batch.float()

        #-------------------------------
        # charging / supplying vehicles 
        #-------------------------------
        at_depot = self.is_depot(self.vehicle_position_id) # [batch_size x num_vehicles]
        charge_phase_vehicles = (self.vehicle_phase == self.phase_id["charge"]) # [batch_size x num_vehicles]
        #-----------------------------
        # charging (depot -> vehicle)
        #-----------------------------
        queued_vehicles = self.charge_queue.sum(1) > 1 # [batch_size x num_vehicles]
        charging_vehicles = charge_phase_vehicles & at_depot & update_batch.unsqueeze(-1) & ~queued_vehicles # [batch_size x num_vehicles]
        charging_vehicle_position_idx = (self.vehicle_position_id - self.num_locs) * charging_vehicles.long()
        self.vehicle_curr_battery += self.depot_discharge_rate.gather(-1, charging_vehicle_position_idx) * elapsed_time.unsqueeze(-1) * charging_vehicles.float() # [batch_size x num_vehicles]
        #---------------------------------
        # supplying (vehicle -> location)
        #---------------------------------
        supplying_vehicles = charge_phase_vehicles & ~at_depot & update_batch.unsqueeze(-1) # [batch_size x num_vehicles]
        # location battery charge
        # NOTE: In locs where a vehicle is staying, the battery of the locs incrases by loc_consump_rate * elapsed_time, not vehicle_discarge_rate * elasped_time.
        # However, as the battery of the locs should be full when a vehicle is staying and it is clamped by max_cap later, we ignore this mismatch here.
        supplying_vehicle_position_idx = self.vehicle_position_id * supplying_vehicles.long() # [batch_size x num_vehicles]
        self.loc_curr_battery.scatter_reduce_(-1, 
                                                supplying_vehicle_position_idx, 
                                                self.vehicle_discharge_rate * elapsed_time.unsqueeze(-1) * supplying_vehicles.float(), 
                                                reduce="sum")
        # vechicle battery consumption (consumption rate is different b/w waiting vehicles and not waiting ones)
        # not waiting
        supplying_not_wait_vehicles = supplying_vehicles & ~self.wait_vehicle # [batch_size x num_vehicles]
        self.vehicle_curr_battery -= self.vehicle_discharge_rate * elapsed_time.unsqueeze(-1) * supplying_not_wait_vehicles.float()
        # waiting
        supplying_wait_vehicles = supplying_vehicles & self.wait_vehicle
        supplying_vehicle_position_idx_ = self.vehicle_position_id * supplying_wait_vehicles.long()
        self.vehicle_curr_battery -= self.loc_consump_rate.gather(-1, supplying_vehicle_position_idx_) * elapsed_time.unsqueeze(-1) * (supplying_wait_vehicles).float() # [batch_size x num_vehicles]
        
        #----------------------------------
        # battery consumption of locations
        #----------------------------------
        self.loc_curr_battery -= self.loc_consump_rate * (elapsed_time * update_batch.float()).unsqueeze(-1)
        
        # TODO:
        # print(self.vehicle_curr_battery[self.vehicle_curr_battery<0])
        # location battery is always greater (less) than 0 (capacity)
        self.vehicle_curr_battery = self.vehicle_curr_battery.clamp(min=0.0)
        self.vehicle_curr_battery = self.vehicle_curr_battery.clamp(max=self.vehicle_cap)

        #----------------
        # update penalty
        #----------------
        down_locs = (self.loc_curr_battery - self.loc_min_battery) <= 0.0 # SMALL_VALUE [batch_size x num_locs]
        # ignore penalty in skipped episodes
        num_empty_locs = ((-self.loc_curr_battery + self.loc_min_battery) / self.loc_consump_rate) * down_locs * (~self.skip.unsqueeze(-1)) # [batch_size x num_locs]
        # empty_locs = ((-self.loc_curr_battery + self.loc_min_battery)[down_locs] / self.loc_consump_rate[down_locs]) # 1d
        # num_empty_locs = torch.zeros((self.batch_size, self.num_locs), dtype=torch.float, device=self.device).masked_scatter_(down_locs, empty_locs)
        # num_empty_locs[self.skip] = 0.0 # ignore penalty in skipped episodes
        self.penalty_empty_locs += num_empty_locs.sum(-1) * update_batch / self.num_locs # [batch_size]
        # location battery is always greater (less) than minimum battery (capacity)
        self.loc_curr_battery = self.loc_curr_battery.clamp(min=self.loc_min_battery)
        self.loc_curr_battery = self.loc_curr_battery.clamp(max=self.loc_cap)

        #---------------------
        # update unavail_time
        #---------------------
        # decrease unavail_time
        queued_vehicles = self.charge_queue.sum(1) > 1 # [batch_size x num_vehicles]
        update_vehicles = ~queued_vehicles & update_batch.unsqueeze(-1) # [batch_size x num_vehicles]
        self.vehicle_unavail_time -= elapsed_time.unsqueeze(-1) * update_vehicles
        
        #---------------------
        # update current time
        #---------------------
        self.current_time += elapsed_time * update_batch

        #---------------------
        # visualize the state
        #---------------------
        if self.fname is not None:
            vis_batch = update_batch & ~self.skip & (torch.abs(elapsed_time) > SMALL_VALUE)
            self.visualize_state_batch(vis_batch)

        # update unavail time
        if align_phase:
            at_depot = self.is_depot(next_node_id).unsqueeze(-1) # [batch_size x 1]
            next_vehicles_on_update_batch = next_vehicle_mask & update_batch.unsqueeze(-1) # [batch_size x num_vehicles]
            # clear (zero out) unavail time of next vehicles on updated batch
            self.vehicle_unavail_time *= ~next_vehicles_on_update_batch # 0 or 1 [batch_size x num_vehicles]
            
            #-------------------------
            # moving -> pre operation: 
            #-------------------------
            next_vehicle_on_move = next_vehicles_on_update_batch & (self.vehicle_phase == self.phase_id["move"]) # [batch_size x num_vehicles]
            if next_vehicle_on_move.sum() > 0:
                self.vehicle_unavail_time += self.vehicle_pre_time * next_vehicle_on_move # [batch_size x num_vehicles]
                self.vehicle_move_time *= ~next_vehicle_on_move # reset move time
                # add supplying vehicles to charge-query
                head = self.charge_queue.min(-1)[0] # [batch_size x num_depots]
                destination_depot_mask = self.get_depot_mask(next_node_id) # [batch_size x num_depots]
                update_query_mask = (~self.wait_vehicle & next_vehicle_on_move).unsqueeze(1) & destination_depot_mask.unsqueeze(-1) # [batch_size x num_depots x num_vehicles]
                # self.charge_queue[update_query_mask] = head.unsqueeze(-1).expand_as(self.charge_queue)[update_query_mask] + 1
                self.charge_queue += (head + 1).unsqueeze(-1) * update_query_mask # [batch_size x num_depots x num_vehicles]
            
            #---------------------------
            # pre operation -> charging
            #---------------------------
            next_vehicle_on_pre = next_vehicles_on_update_batch & (self.vehicle_phase == self.phase_id["pre"]) # [batch_size x num_vehicles]
            if next_vehicle_on_pre.sum() > 0:
                self.vehicle_unavail_time += self.vehicle_work_time * next_vehicle_on_pre
                self.vehicle_pre_time *= ~next_vehicle_on_pre # reset pre time
            
            #----------------------------
            # charging -> post operation
            #----------------------------
            next_vehicle_on_charge = next_vehicles_on_update_batch & (self.vehicle_phase == self.phase_id["charge"]) # [batch_size x num_vehicles]
            if next_vehicle_on_charge.sum() > 0:
                self.vehicle_unavail_time += self.vehicle_post_time * next_vehicle_on_charge
                self.vehicle_work_time *= ~next_vehicle_on_charge

            #--------------
            # update phase
            #--------------
            self.vehicle_phase += next_vehicles_on_update_batch.long()
        else:
            #----------------------------------------------
            # post operation -> move (determine next node)
            #----------------------------------------------
            # update charge-queue
            # do not change charge queue when the next vehicle is waiting
            # because the waiting vehicles are not added to the queue
            destination_depot_mask = self.get_depot_mask(next_node_id) & ~self.wait_vehicle[next_vehicle_mask].unsqueeze(-1) # [batch_size x num_depots]
            # self.charge_queue[destination_depot_mask] -= 1 # [batch_size x num_depots x num_vehicles]
            self.charge_queue -= destination_depot_mask.long().unsqueeze(-1) # [batch_size x num_depots x num_vehicles]
            self.charge_queue = self.charge_queue.clamp(0)
            # reset the waiting flag of the selected vehicles
            self.wait_vehicle.scatter(-1, next_vehicle_id.to(torch.int64).unsqueeze(-1), False)
            # vehiclel_unavail_time of the selected vehicle is updated with travel time in the early step of next called self.update
            self.vehicle_post_time *= ~next_vehicle_mask
        
        #-------------------
        # update skip batch
        #-------------------
        # end flags
        self.end = self.current_time >= self.time_horizon # [batch_size]
        # skip
        self.skip = self.end # [batch_size]

    #---------
    # masking
    #---------
    def update_mask(self, next_node_id, next_vehicle_mask):
        #---------------------------------------------------------------
        # mask: 0 -> infeasible, 1 -> feasible [batch_size x num_nodes]
        #---------------------------------------------------------------
        mask = torch.ones(self.batch_size, self.num_nodes, dtype=torch.int32, device=self.device) # [batch_size x num_nodes]
        # EV cannot discharge power when its battery rearches the limit, so EV should return to a depot at that time.
        self.return_to_depot_when_discharge_limit_rearched(mask, next_vehicle_mask)
        # mask 0: if a selected vehicle is out of battery, we make it return to a depot
        self.mask_unreturnable_nodes(mask, next_node_id, next_vehicle_mask)
        # mask 2: forbits vehicles to move between two different depots
        # i.e., if a selcted vechile is currently at a depot, it cannot visit other depots in the next step (but it can stay in the same depot)
        # self.mask_depot_to_other_depots(mask, next_node_id)
        # mask 3: vehicles cannot visit a location/depot that other vehicles are visiting
        self.mask_visited_locs(mask)
        # mask 4: forbit vehicles to visit depots that have small discharge rate
        self.remove_small_depots(mask, next_node_id)
        # mask 5: in skipped episodes(instances), the selcted vehicles always stay in the same place
        self.mask_skipped_episodes(mask, next_node_id)
        return mask

    def return_to_depot_when_discharge_limit_rearched(self, mask, next_vehicle_mask):
        rearch_discharge_lim = (self.vehicle_curr_battery <= self.vehicle_discharge_lim + SMALL_VALUE)[next_vehicle_mask] # [batch_size]
        mask[:, :self.num_locs] *= ~rearch_discharge_lim.unsqueeze(-1) # zero out all nodes in the sample where the selected EV rearches the discharge limit

    def mask_unreturnable_nodes(self, mask, next_node_id, next_vehicle_mask):
        """
        There are two patterns:
            1. unreturnable to depot within time horizon
            2. unreturnable to depot without running out of vehicle battery
        """
        # mask 1: guarantee that all the vehicles return to depots within the time horizon
        remaining_time = (self.time_horizon - self.current_time).unsqueeze(-1).clamp(0.0) # [batch_size x 1]
        current_coord = torch.gather(self.coords, 1, next_node_id.view(-1, 1, 1).expand(-1, 1, self.coord_dim)) # [batch_size, 1, coord_dim]
        unavail_depots = self.small_depots.unsqueeze(-1).expand_as(self.depot_coords) # [batch_size x num_depots x coord_dim]
        depot_coords = self.depot_coords + 1e+6 * unavail_depots # set large value for removing small depots [batch_size x num_depots x coord_dim]
        current_to_loc = COEF * torch.linalg.norm(self.loc_coords - current_coord, dim=-1) # [batch_size x num_locs]
        loc_to_depot = COEF * torch.min(torch.cdist(self.loc_coords, depot_coords), -1)[0] # travel time b/w locs and the nearest depot [batch_size x num_locs]
        current_to_loc_time = current_to_loc / self.speed.unsqueeze(-1)
        loc_to_depot_time = loc_to_depot / self.speed.unsqueeze(-1)
        wait_time = self.wait_time * (torch.abs(current_to_loc) < SMALL_VALUE) # [batch_size x num_locs]

        #--------------------------------------------------------------------------------------------------------------
        # vehicles can visit only locations that the vehicles can return to depots within time horizon after the visit
        # i.e. travel time t_(current_node -> next_loc -> depot) + current_time <= time_horizon
        #--------------------------------------------------------------------------------------------------------------
        # loc_charge_time should be wait_time not zero in the locations where a vehicle is waiting,
        # but ignore that because those locations are masked out later 
        runout_battery_loc = ((current_to_loc + loc_to_depot) * self.vehicle_consump_rate[next_vehicle_mask].unsqueeze(-1) # travel consumption
                            #    + self.vehicle_discharge_rate[next_vehicle_mask].unsqueeze(-1) * loc_charge_time # supply consumption: curr_demand + loc_charge_time * self.loc_consump_rate
                               + self.loc_consump_rate * wait_time # supply consumption when waiting
                             ) > self.vehicle_curr_battery[next_vehicle_mask].unsqueeze(-1) + BIT_SMALL_VALUE
        
        # if its battery is zero, the vehicle should return to a depot (this is used only when vehicle_consump_rate = 0)
        battery_zero = torch.abs(self.vehicle_curr_battery[next_vehicle_mask]) < SMALL_VALUE # [batch_size]
        # mask for unreturnable locations
        unreturnable_loc = battery_zero.unsqueeze(-1) | runout_battery_loc # [batch_size x num_locs]
        if self.return_depot_within_time_horizon:
            # ignore the battery change of visited locations (either way, they are masked out later)
            loc_battery_on_arrival = (self.loc_curr_battery - self.loc_consump_rate * (current_to_loc_time + self.pre_time_loc)).clamp(self.loc_min_battery) # [batch_size x num_locs]
            curr_demand = torch.minimum(self.loc_cap - loc_battery_on_arrival, self.vehicle_curr_battery[next_vehicle_mask].unsqueeze(-1)) # [batch_size x num_locs]
            # time limit
            loc_charge_time = curr_demand / (self.vehicle_discharge_rate[next_vehicle_mask].unsqueeze(-1) - self.loc_consump_rate) # [batch_size x num_locs]
            exceed_timehorizon_loc = (current_to_loc_time + self.pre_time_loc + loc_charge_time + self.post_time_loc + loc_to_depot_time + wait_time).gt(remaining_time + BIT_SMALL_VALUE)
            unreturnable_loc |= exceed_timehorizon_loc
        
        #---------------------------------------------------------------------------------------
        # vehicles can visit only depots that the vehicles can arrive there within time horizon
        # i.e. travel time t_(current_node -> depot) + current_time <= time_horizon
        #---------------------------------------------------------------------------------------
        unavail_depots2 = self.get_unavail_depots(next_node_id).unsqueeze(-1).expand_as(self.depot_coords) # [batch_size x num_depots x coord_dim]
        depot_coords2 = self.depot_coords + 1e+6 * unavail_depots2
        current_to_depot = COEF * torch.linalg.norm(depot_coords2 - current_coord, dim=-1) # [batch_size x num_depots]
        current_to_depot_time = current_to_depot / self.speed.unsqueeze(-1) # [batch_size x n_depots]
        # battery
        curr2depot_batt = current_to_depot * self.vehicle_consump_rate[next_vehicle_mask].unsqueeze(-1) # [batch_size x num_depots]
        veh_batt = self.vehicle_curr_battery[next_vehicle_mask].unsqueeze(-1) # [batch_size x 1]
        runout_battery_depot = curr2depot_batt >= veh_batt + BIT_SMALL_VALUE # [batch_size x num_depots]
        unreturnable_depot = runout_battery_depot
        if self.return_depot_within_time_horizon:
            # time
            exceed_timehorizon_depot = (current_to_depot).gt(remaining_time + BIT_SMALL_VALUE) # [batch_size x num_depots]
            unreturnable_depot |= exceed_timehorizon_depot

        # there should be at least one depot that the vehicle can reach
        i = 0; atol_list=[1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1] # TODO: float -> double
        while (((~unreturnable_depot).int().sum(-1) == 0) & ~self.skip).any():
            all_zero = ((~unreturnable_depot).int().sum(-1) == 0).unsqueeze(-1) # [batch_size x 1]
            close_to_runout_battery = torch.isclose(curr2depot_batt, veh_batt, atol=atol_list[i])
            if self.return_depot_within_time_horizon:
                close_to_timehorizon = torch.isclose(current_to_depot_time, remaining_time, atol=atol_list[i]) # [batch_size x num_depots]
                close_to_runout_battery |= close_to_timehorizon
            unreturnable_depot[all_zero & close_to_runout_battery] = False
            i += 1
            if i >= len(atol_list):
                print(self.depot_discharge_rate[all_zero.squeeze(-1)])
                print(f"battery consumption b/w loc2depot: {(current_to_depot * self.vehicle_consump_rate[next_vehicle_mask].unsqueeze(-1))[all_zero.squeeze(-1)].tolist()}")
                print(f"selected vehicle's battery: {self.vehicle_curr_battery[next_vehicle_mask].unsqueeze(-1)[all_zero].tolist()}")
                print(torch.where(all_zero))
                print(f"travel time b/w loc2depot: {current_to_depot_time[all_zero.squeeze(-1)].tolist()}")
                print(f"remaining time: {remaining_time[all_zero].tolist()}")
                assert False, "some vehicles could not return to any depots within time horizon due to numerical error."
        
        #--------------------------
        # update unreturnable mask
        #--------------------------
        unreturnable_mask = torch.cat((unreturnable_loc, unreturnable_depot), 1) # [batch_size x num_nodes]
        mask *= ~unreturnable_mask
    
    def mask_visited_locs(self, mask: torch.Tensor):
        """
        Remove visited locs from the next-node candidates
        
        Parameters
        ----------
        mask: torch.LongTensor [batch_size x num_nodes]
        """
        reserved_loc = torch.full((self.batch_size, self.num_nodes), False, device=self.device)
        reserved_loc.scatter_(1, self.vehicle_position_id, True)
        reserved_loc[:, self.num_locs:] = False
        mask *= ~reserved_loc

    def mask_depot_to_other_depots(self, mask: torch.Tensor, next_node_id: torch.Tensor):
        """
        A mask for removing moving between different two depots
        
        Parameters
        ----------
        mask: torch.LongTesnor [batch_size x num_nodes]
        next_node_id: torch.LongTensor [batch_size]
        """
        at_depot = next_node_id.ge(self.num_locs).unsqueeze(1) # [batch_size x 1]
        other_depot = self.node_arange_idx.ne(next_node_id.unsqueeze(1)) # [batch_size x num_nodes]
        other_depot[:, :self.num_locs] = False # ignore locations here
        mask *= ~(at_depot & other_depot)

    def remove_small_depots(self, mask: torch.Tensor, next_node_id: torch.Tensor):
        """
        A mask for removing small depots, which have low discharge_rate
        """
        unavail_depots = self.get_unavail_depots(next_node_id) # [batch_size x num_depots]
        unavail_nodes = torch.cat((torch.full((self.batch_size, self.num_locs), False).to(self.device), unavail_depots), -1) # [batch_size x num_nodes]
        mask *= ~unavail_nodes
        return mask
    
    def get_unavail_depots(self, next_node_id: torch.Tensor):
        stayed_depots = self.get_depot_mask(next_node_id) # [batch_size x num_depots]
        # if the initial depot is a small depot, the vehicle can stay there
        return ~stayed_depots & self.small_depots # (small depots) and (not visited) [batch_size x num_depots]

    def get_unavail_depots2(self, next_node_id: torch.Tensor):
        return self.small_depots
    
    def mask_skipped_episodes(self, mask: torch.Tensor, next_node_id: torch.Tensor):
        current_node = self.node_arange_idx.eq(next_node_id.unsqueeze(1)).int() # [batch_size x num_nodes]
        mask[self.skip] = current_node[self.skip]

    def get_inputs(self):
        """
        Returns
        -------
        node_feats: torch.tensor [batch_size x num_nodes x node_feat_dim]
            input features of nodes
        vehicle_feats: torch.tensor [batch_size x num_vehicles x vechicle_feat_dim]
            input features of vehicles
        """
        visit_mask = torch.full((self.batch_size, self.num_nodes), 0.0, device=self.device)
        visit_mask.scatter_(1, self.vehicle_position_id, 1.0)
        # for locations (loc_dim = 1+2+1+1+1+1 = 7)
        loc_feats = torch.cat((
            visit_mask[:, :self.num_locs, None], # visited by an EV?
            self.loc_coords,  # [batch_size x num_locs x coord_dim]
            self.loc_cap.unsqueeze(-1) / self.max_cap, # [batch_size x num_locs x 1]
            self.loc_consump_rate.unsqueeze(-1) / self.max_cap, # [batch_size x num_locs x 1]
            self.loc_curr_battery.unsqueeze(-1) / self.max_cap,  # [batch_size x num_locs x 1]
            (self.loc_curr_battery / self.loc_consump_rate).unsqueeze(-1) # expected time to go down [batch_size x num_locs x 1]
        ), -1)
        # for depots (depot_dim = 1+2+1 = 4)
        depot_feats = torch.cat((
            visit_mask[:, self.num_locs:, None], # visited by an EV?
            self.depot_coords, # [batch_size x num_depots x coord_dim]
            self.depot_discharge_rate.unsqueeze(-1) / self.max_cap # [batch_size x num_depots x 1]
        ), -1)
        # for vehicles (vehicle_dim = 1+2+1+1++4+1+1 = 11)
        curr_vehicle_coords = self.coords.gather(1, self.vehicle_position_id.unsqueeze(-1).expand(self.batch_size, self.num_vehicles, self.coord_dim)) # [batch_size x num_vehicles x coord_dim]
        vehicle_phase_time = torch.concat((
            self.vehicle_move_time.unsqueeze(-1),
            self.vehicle_pre_time.unsqueeze(-1),
            self.vehicle_work_time.unsqueeze(-1),
            self.vehicle_post_time.unsqueeze(-1)
        ), -1) # [batch_size x num_vehicles x 4]
        vehicle_phase_time.scatter_(-1, self.vehicle_phase.unsqueeze(-1), self.vehicle_unavail_time.unsqueeze(-1)) # [batch_size x num_vehicles x 4]
        vehicle_phase_time_sum = vehicle_phase_time.sum(-1, keepdim=True)
        vehicle_feats = torch.cat((
            self.vehicle_cap.unsqueeze(-1) / self.max_cap, # [batch_size x num_vehicles] -> [batch_size x num_vehicles x 1]
            curr_vehicle_coords, # [batch_size x num_vehicles x coord_dim]
            self.is_depot(self.vehicle_position_id).unsqueeze(-1).to(torch.float), # [batch_size x num_vehicles x 1] at {depot: 0, locations: 1}
            self.vehicle_phase.unsqueeze(-1) / self.phase_id_max, # [batch_size x num_vehicles] -> [batch_size x num_vehicles x 1] the phase of vehicles
            vehicle_phase_time, # remaining time of move, pre-operation, charge/supply, and post-operation [batch_size x num_vehicles x 4]
            vehicle_phase_time_sum, # / (vehicle_phase_time_sum.max(-1, keepdim=True)[0] + SMALL_VALUE), # total unavail time [batch_size x num_vehicles x 1]
            self.vehicle_curr_battery.unsqueeze(-1) / self.max_cap # [batch_size x num_vehicles x 1]
            # self.current_time[:, None, None].expand(-1, self.num_vehicles, 1) / self.time_horizon # [batch_size] -> [batch_size x num_vehicles x 1] 
        ), -1)
        return loc_feats, depot_feats, vehicle_feats

    def get_mask(self):
        """
        Returns
        -------
        mask: torch.tensor [batch_size x num_nodes]
        """
        return self.mask

    def get_selected_vehicle_id(self):
        """
        Returns 
        -------
        next_vehicle_id [batch_size]
        """
        return self.next_vehicle_id.to(torch.int64)

    def all_finished(self):
        """
        Returns
        -------
        end: torch.tensor [batch_size]
        """
        return self.end.all()

    def get_rewards(self):
        # compute the last penalty
        # remaining_time = self.time_horizon - self.current_time # [batch_size]
        # self.loc_curr_battery -= self.loc_consump_rate * remaining_time.unsqueeze(-1)
        # down_locs = (self.loc_curr_battery - self.loc_min_battery) < SMALL_VALUE
        # num_empty_locs = down_locs.count_nonzero(-1) * remaining_time # [batch_size]
        # num_empty_locs = ((self.loc_curr_battery - self.loc_min_battery)[down_locs] / self.loc_consump_rate[down_locs]).sum(-1)
        # num_empty_locs[self.skip] = 0 # ignore penalty in skipped episodes
        # self.penalty_empty_locs += num_empty_locs / self.num_locs # [batch_size]
        # normalization
        penalty = self.penalty_empty_locs / self.time_horizon
        tour_length = self.tour_length / self.num_vehicles
        return {"tour_length": tour_length, "penalty": penalty}

    def visualize_state_batch(self, visualized_batch: torch.BoolTensor):
        if self.episode_step == 0 or UNEQUAL_INTERVAL:
            for batch in range(1):
                if visualized_batch[batch] == False:
                    continue
                self.visualize_state(batch, 
                                    self.current_time[batch].item(), 
                                    self.vehicle_curr_battery[batch], 
                                    self.loc_curr_battery[batch], 
                                    ((self.loc_curr_battery[batch] - self.loc_min_battery) <= 0.0).sum().item(),
                                    self.vehicle_unavail_time[batch])
        else:
            for batch in range(1):
                if visualized_batch[batch] == False:
                    continue
                prev_time      = self.time_history[batch][-1]
                curr_time      = self.current_time[batch].item()
                prev_veh_batt  = copy.deepcopy(self.vehicle_batt_history[batch])
                prev_loc_batt  = copy.deepcopy(self.loc_batt_history[batch])
                prev_down_locs = self.down_history[batch][-1]
                curr_veh_unavail_time = self.vehicle_unavail_time[batch].clamp(0.0).detach().clone()
                time_interval  = curr_time - prev_time
                dts = np.arange(OUTPUT_INTERVAL, time_interval, OUTPUT_INTERVAL).tolist()
                if len(dts) != 0:
                    if time_interval - dts[-1] <= OUTPUT_INTERVAL / 4:
                        dts[-1] = time_interval
                    else:
                        dts.append(time_interval)
                else:
                    dts.append(time_interval)
                for dt in dts:
                    ratio = dt / time_interval
                    curr_veh_batt = torch.tensor([
                        interpolate_line(prev_veh_batt[vehicle_id][-1], self.vehicle_curr_battery[batch][vehicle_id].item(), ratio)
                        for vehicle_id in range(self.num_vehicles)
                    ]) # [num_vehicles]
                    curr_loc_batt = torch.tensor([
                        interpolate_line(prev_loc_batt[loc_id][-1], self.loc_curr_battery[batch][loc_id].item(), ratio) 
                        for loc_id in range(self.num_locs)
                    ]) # [num_locs]
                    curr_down_locs = interpolate_line(prev_down_locs, ((self.loc_curr_battery[batch] - self.loc_min_battery) <= 0.0).sum().item(), ratio) # [1]
                    veh_unavail_time = curr_veh_unavail_time + (time_interval - dt)
                    self.visualize_state(batch, prev_time + dt, curr_veh_batt, curr_loc_batt, curr_down_locs, veh_unavail_time)

    def visualize_state(self, 
                        batch: int, 
                        curr_time: float,
                        curr_veh_batt: torch.FloatTensor,
                        curr_loc_batt: torch.FloatTensor,
                        curr_down_locs: float,
                        veh_unavail_time: torch.FloatTensor) -> None:
        #-----------------
        # battery history
        #-----------------
        self.time_history[batch].append(curr_time)
        for vehicle_id in range(self.num_vehicles):
            self.vehicle_batt_history[batch][vehicle_id].append(curr_veh_batt[vehicle_id].item())
        for loc_id in range(self.num_locs):
            self.loc_batt_history[batch][loc_id].append(curr_loc_batt[loc_id].item())
        self.down_history[batch].append(curr_down_locs)

        #---------------
        # visualziation
        #---------------
        if SAVE_PICTURE:
            fig = plt.figure(figsize=(20, 12))
            gs = fig.add_gridspec(ncols=2, nrows=3, width_ratios=[1, 1.5])
            ax = fig.add_subplot(gs[:, 1])
            # current state
            loc_battery = torch2numpy(curr_loc_batt)         # [num_locs]
            vehicle_battery = torch2numpy(curr_veh_batt) # [num_vehicles]
            loc_cap = torch2numpy(self.loc_cap[batch])                      # [num_locs]
            loc_coords = torch2numpy(self.loc_coords[batch])                # [num_locs x coord_dim]
            depot_coords = torch2numpy(self.depot_coords[batch])            # [num_depots x coord_dim]
            coords = np.concatenate((loc_coords, depot_coords), 0)          # [num_nodes x coord_dim]
            vehicle_cap = torch2numpy(self.vehicle_cap[batch])              # [num_vehicles]
            x_loc = loc_coords[:, 0]; y_loc = loc_coords[:, 1]
            x_depot = depot_coords[:, 0]; y_depot = depot_coords[:, 1]
            # visualize nodes
            for id in range(self.num_locs):
                ratio = loc_battery[id] / loc_cap[id]
                add_base(x_loc[id], y_loc[id], ratio, ax)
            ax.scatter(x_depot, y_depot, marker="*", c="black", s=200, zorder=3)
            # visualize vehicles
            cmap = get_cmap(self.num_vehicles)
            for vehicle_id in range(self.num_vehicles):
                ratio = vehicle_battery[vehicle_id] / vehicle_cap[vehicle_id]
                vehicle_phase = self.vehicle_phase[batch][vehicle_id]
                vehicle_position_id = self.vehicle_position_id[batch][vehicle_id]
                if vehicle_phase != self.phase_id["move"]:
                    vehicle_x = coords[vehicle_position_id, 0]
                    vehicle_y = coords[vehicle_position_id, 1]
                    add_vehicle(vehicle_x, vehicle_y, ratio, vehicle_battery[vehicle_id], cmap(vehicle_id), ax)
                else:
                    vehicle_position_id_prev = self.vehicle_position_id_prev[batch][vehicle_id]
                    speed = self.speed[batch]
                    start = coords[vehicle_position_id_prev, :]
                    end   = coords[vehicle_position_id, :]
                    distance = np.linalg.norm(start - end)
                    curr_position = interpolate_line(start, end, (1.0 - speed * veh_unavail_time[vehicle_id] / distance).item())
                    ax.plot([start[0], curr_position[0]], [start[1], curr_position[1]], zorder=0, linestyle="-", color=cmap(vehicle_id))         # passed path
                    ax.plot([curr_position[0], end[0]], [curr_position[1], end[1]], zorder=0, alpha=0.5, linestyle="--", color=cmap(vehicle_id)) # remaining path
                    add_vehicle(curr_position[0], curr_position[1], ratio, vehicle_battery[vehicle_id], cmap(vehicle_id), ax)
            ax.set_title(f"current time = {curr_time:.3f} h", y=-0.05, fontsize=18)
            ax.set_xlim(-0.05, 1.05); ax.set_ylim(-0.05, 1.05)
            ax.get_xaxis().set_visible(False); ax.get_yaxis().set_visible(False)
            ax.set_aspect(1)

            #----------------------------
            # add history plot until now
            #----------------------------
            time_horizon = self.time_horizon.cpu().item()
            max_veh_batt = torch.ceil(self.vehicle_cap[batch].max() / 10).cpu().item() * 10
            max_loc_batt = torch.ceil(self.loc_cap[batch].max() / 10).cpu().item() * 10
            max_num_locs = math.ceil(self.num_locs / 10) * 10
            # EV battery history
            ax_ev = fig.add_subplot(gs[0, 0])
            for vehicle_id in range(self.num_vehicles):
                ax_ev.plot(self.time_history[batch], list(self.vehicle_batt_history[batch][vehicle_id]), alpha=0.7, color=cmap(vehicle_id))
            ax_ev.set_xlim(0, time_horizon)
            ax_ev.set_ylim(0, max_veh_batt)
            ax_ev.get_xaxis().set_visible(False)
            ax_ev.axvline(x=self.time_history[batch][-1], ymin=-1.2, ymax=1, c="black", lw=1.5, zorder=0, clip_on=False)
            ax_ev.set_ylabel("EV battery (kWh)", fontsize=18)
            # Base station battery history
            ax_base = fig.add_subplot(gs[1, 0])
            for loc_id in range(self.num_locs):
                ax_base.plot(self.time_history[batch], list(self.loc_batt_history[batch][loc_id]), alpha=0.7)
            ax_base.set_xlim(0, time_horizon)
            ax_base.set_ylim(0, max_loc_batt)
            ax_base.get_xaxis().set_visible(False)
            ax_base.axvline(x=self.time_history[batch][-1], ymin=-1.2, ymax=1, c="black", lw=1.5, zorder=0, clip_on=False)
            ax_base.set_ylabel("Base station battery (kWh)", fontsize=18)
            # Num. of downed base stations
            ax_down = fig.add_subplot(gs[2, 0])
            ax_down.plot(self.time_history[batch], self.down_history[batch])
            ax_down.set_xlim(0, time_horizon)
            ax_down.set_ylim(0, max_num_locs)
            ax_down.axvline(x=self.time_history[batch][-1], ymin=0, ymax=1, c="black", lw=1.5, zorder=0, clip_on=False)
            ax_down.set_xlabel("Time (h)", fontsize=18)
            ax_down.set_ylabel("# downed base stations", fontsize=18)

            #---------------
            # save an image
            #---------------
            fig.subplots_adjust(left=0.03, right=1, bottom=0.05, top=0.98, wspace=0.05)
            fname = f"{self.fname}-{batch}/png/tour_state{self.episode_step}.png"
            os.makedirs(f"{self.fname}-{batch}/png", exist_ok=True)
            plt.savefig(fname, dpi=DPI)
            plt.close()

        self.episode_step += 1

    def output_batt_history(self):
        batch = 0
        os.makedirs(f"{self.fname}-sample{batch}", exist_ok=True)

        # save the image of batt history
        fig = plt.figure(figsize=(10, 30))
        ax1 = fig.add_subplot(311)
        ax2 = fig.add_subplot(312)
        ax3 = fig.add_subplot(313)
        for vehicle_id in range(self.num_vehicles):
            ax1.plot(self.time_history[batch], list(self.vehicle_batt_history[batch][vehicle_id]))
        for loc_id in range(self.num_locs):
            ax2.plot(self.time_history[batch], list(self.loc_batt_history[batch][loc_id]))
        ax3.plot(self.time_history[batch], self.down_history[batch])
        ax1.set_xlabel("Time (h)")
        ax1.set_ylabel("EVs' battery (KW)")
        ax2.set_xlabel("Time (h)")
        ax2.set_ylabel("Base stations' battery (KW)")
        ax3.set_xlabel("Time (h)")
        ax3.set_ylabel("Number of downed base stations")
        plt.savefig(f"{self.fname}-sample{batch}/batt_history.png", dpi=DPI)
        plt.close()
        
        # save raw data
        hisotry_data = {
            "time": self.time_history[batch],
            "veh_batt": self.vehicle_batt_history[batch],
            "loc_batt": self.loc_batt_history[batch],
            "down_loc": self.down_history[batch]
        }
        with open(f"{self.fname}-sample{batch}/history_data.pkl", "wb") as f:
            pickle.dump(hisotry_data, f)
    
    def output_gif(self):
        for batch in range(1):
            anim_type = "mp4"
            out_fname = f"{self.fname}-{batch}/EVRoute.{anim_type}"
            seq_fname = f"{self.fname}-{batch}/png/tour_state%d.png"
            output_animation(out_fname, seq_fname, anim_type)

def torch2numpy(tensor: torch.Tensor):
    return tensor.cpu().detach().numpy().copy()

def add_base(x, y, ratio, ax):
    width = 0.01 * 1.5
    height = 0.015 * 1.5
    height_mod = ratio * height
    if ratio > 0.5:
        battery_color = "limegreen"
    elif ratio > 0.3:
        battery_color = "gold"
    else:
        battery_color = "red"
    ec = "red" if ratio < 1e-9 else "black"

    frame = patches.Rectangle(xy=(x-width/2, y-height/2), width=width, height=height, fill=False, ec=ec)
    battery = patches.Rectangle(xy=(x-width/2, y-height/2), width=width, height=height_mod, facecolor=battery_color, linewidth=.5, ec="black")
    ax.add_patch(battery)
    ax.add_patch(frame) 

def add_vehicle(x, y, ratio, batt, color, ax):
    offst = 0.03
    BATT_OFFSET = 0.025
    # vehicle_battery
    width = 0.015 * 1.2
    height = 0.01 * 1.2
    width_mod = ratio * width
    ec = "red" if ratio < 1e-9 else "black"
    frame = patches.Rectangle(xy=(x-width/2, y-height/2+offst+BATT_OFFSET), width=width, height=height, fill=False, ec=ec)
    battery = patches.Rectangle(xy=(x-width/2, y-height/2+offst+BATT_OFFSET), width=width_mod, height=height, facecolor=color, linewidth=.5, ec="black")
    ax.add_patch(battery)
    ax.add_patch(frame)

    # add remaining battery
    ax.text(x-0.02, y+0.07, f"{batt: .1f}", fontsize=10)
    
    # vehicle
    original_img = plt.imread("images/ev_image.png")
    vehicle_img = np.where(original_img == (1., 1., 1., 1.), (color[0], color[1], color[2], color[3]), original_img)
    vehicle_img = OffsetImage(vehicle_img, zoom=0.25)
    ab = AnnotationBbox(vehicle_img, (x, y+offst), xycoords='data', frameon=False)
    ax.add_artist(ab)

def get_cmap(num_colors: int):
    if num_colors <= 10:
        cm_name = "tab10"
    elif num_colors <= 20:
        cm_name = "tab20"
    else:
        assert False
    return cm.get_cmap(cm_name)

def output_animation(out_fname, seq_fname, type="gif"):
    if type == "gif":
        cmd = f"ffmpeg -r {FPS} -i {seq_fname} -r {FPS} {out_fname}"
    else:
        cmd = f"ffmpeg -r {FPS} -i {seq_fname} -vcodec libx264 -pix_fmt yuv420p -r {FPS} {out_fname}"
    subprocess.call(cmd, shell=True)

def interpolate_line(start, end, ratio):
    return ratio * (end - start) + start


--------------------------------------------------------------------------------
文件路径: /Users/dxk/Downloads/evrp-eps-main/models/am_encoder.py
--------------------------------------------------------------------------------

import torch
import torch.nn as nn
import math

class AMEncoder(nn.Module):
    def __init__(self, 
                 loc_dim: int,
                 depot_dim: int,
                 vehicle_dim: int,
                 emb_dim: int,
                 num_heads: int,
                 num_mha_layers: int,
                 dropout: float = 0.0):
        super().__init__()
        self.loc_dim = loc_dim
        self.depot_dim = depot_dim 
        self.emb_dim = emb_dim
        self.dim_feedforward = 2 * emb_dim
        self.num_mha_layers = num_mha_layers

        # initial embedding
        self.init_linear_loc     = nn.Linear(loc_dim, emb_dim)
        self.init_linear_depot   = nn.Linear(depot_dim, emb_dim)
        self.init_linear_vehicle = nn.Linear(vehicle_dim, emb_dim)
        # Transformer Encoder
        # for nodes (locations + depots)
        node_mha_layer = nn.TransformerEncoderLayer(d_model=emb_dim, 
                                                    nhead=num_heads,
                                                    dim_feedforward=self.dim_feedforward,
                                                    dropout=dropout,
                                                    batch_first=True)
        self.node_mha = nn.TransformerEncoder(node_mha_layer, num_layers=num_mha_layers)
        # for vehicles
        vehicle_mha_layer = nn.TransformerEncoderLayer(d_model=emb_dim, 
                                                       nhead=num_heads,
                                                       dim_feedforward=self.dim_feedforward,
                                                       dropout=dropout,
                                                       batch_first=True)
        self.vehicle_mha = nn.TransformerEncoder(vehicle_mha_layer, num_layers=num_mha_layers)

        # params initialization
        self.reset_parameters()

    def reset_parameters(self):
        for param in self.parameters():
            stdv = 1. / math.sqrt(param.size(-1))
            param.data.uniform_(-stdv, stdv)

    def forward(self,
                loc_feats: torch.Tensor,
                depot_feats: torch.Tensor,
                vehicle_feats: torch.Tensor):
        """
        Paramters
        ---------

        Returns
        -------

        """
        # initial embeddings
        loc_emb   = self.init_linear_loc(loc_feats)     # [batch_size x num_locs x emb_dim]
        depot_emb = self.init_linear_depot(depot_feats) # [batch_size x num_depots x emb_dim]
        node_emb  = torch.cat((loc_emb, depot_emb), 1)  # [batch_size x num_nodes x emb_dim]
        vehicle_emb = self.init_linear_vehicle(vehicle_feats) # [batch_size x num_vehicles x emb_dim]
        # transformer encoding
        node_emb = self.node_mha(node_emb) # [batch_size x num_nodes x emb_dim]
        vehicle_emb = self.vehicle_mha(vehicle_emb) # [batch_size x num_vehicles x emb_dim]
        return node_emb, vehicle_emb

# class SkipConnection(nn.Module):
#     def __init__(self, module):
#         super().__init__()
#         self.module = module

#     def forward(self, input):
#         return input + self.module(input)

# class MultiHeadAttention(nn.Module):
#     def __init__(self,
#                  n_heads,
#                  input_dim,
#                  embed_dim):
#         super().__init__()
#         self.n_heads = n_heads
#         self.input_dim = input_dim
#         self.embed_dim = embed_dim
#         self.head_dim = embed_dim // n_heads
#         self.norm_factor = 1 / math.sqrt(self.head_dim)
        
#         self.w_q = nn.Parameter(torch.Tensor(n_heads, input_dim, self.head_dim))
#         self.w_k = nn.Parameter(torch.Tensor(n_heads, input_dim, self.head_dim))
#         self.w_v = nn.Parameter(torch.Tensor(n_heads, input_dim, self.head_dim))
#         self.w_o = nn.Parameter(torch.Tensor(n_heads, self.head_dim, embed_dim))
        
#         self.reset_parameters()

#     def reset_parameters(self):
#         for param in self.parameters():
#             stdv = 1. / math.sqrt(param.size(-1))
#             param.data.uniform_(-stdv, stdv)

#     def forward(self, embedded_inputs):
#         """
#         Transformer's self-attention-based aggregation
        
#         Parameters
#         -----------
#         embedded_inputs: torch.FloatTensor [batch_size x num_nodes(or num_agents) x emb_dim]
#             embeddings of nodes / agents
#         Returns
#         -------
#         out: torch.FloatTensor [batch_size x num_nodes(or num_agents) x context_dim] 
#             context of nodes / agents
#         """
#         batch_size, seq_length, input_dim = embedded_inputs.size()

#         # compute query, key, value
#         hflat = embedded_inputs.contiguous().view(-1, input_dim) # [(batch_size*seq_length) x input_size]
#         shp = (self.n_heads, batch_size, seq_length, self.head_dim) # split embeddings into num. of heads
#         # [n_heads x (batch_size*seq_length) x head_dim] -> [n_heads x batch_size x seq_length x head_dim]
#         q = torch.matmul(hflat, self.w_q).view(shp)
#         k = torch.matmul(hflat, self.w_k).view(shp)
#         v = torch.matmul(hflat, self.w_v).view(shp)

#         # compute attention coefficients
#         # [H x B x L x D] x [H x B x D x L] -> [H x B x L x L]
#         compatibility = self.norm_factor * torch.matmul(q, k.transpose(2, 3)) # dim. is the same as attn's one
#         attn = torch.softmax(compatibility, dim=-1) # [num_head x batch_size x seq_length x seq_length(attention coef.)]

#         # attention-based neighbor aggregation
#         # [H x B x L x L] x [H x B x L x H] -> [H x B x L x H]
#         heads = torch.matmul(attn, v) # [num_head x batch_size x seq_length x head_dim]

#         # aggregate heads
#         out = torch.mm(
#             heads.permute(1, 2, 0, 3).contiguous().view(-1, self.n_heads * self.head_dim), # concat: [batch_size x seq_length x embed_dim]
#             self.w_o.view(-1, self.embed_dim) # [embed_dim x embed_dim]
#         ).view(batch_size, seq_length, self.embed_dim)

#         return out

# class Normalization(nn.Module):
#     def __init__(self, embed_dim, normalization='batch'):
#         super().__init__()

#         normalizer_class = {
#             'batch': nn.BatchNorm1d,
#             'instance': nn.InstanceNorm1d
#         }.get(normalization, None)

#         self.normalizer = normalizer_class(embed_dim, affine=True)

#         # Normalization by default initializes affine parameters with bias 0 and weight unif(0,1) which is too large!
#         # self.init_parameters()

#     def init_parameters(self):
#         for name, param in self.named_parameters():
#             stdv = 1. / math.sqrt(param.size(-1))
#             param.data.uniform_(-stdv, stdv)

#     def forward(self, input):
#         if isinstance(self.normalizer, nn.BatchNorm1d):
#             return self.normalizer(input.view(-1, input.size(-1))).view(*input.size())
#         elif isinstance(self.normalizer, nn.InstanceNorm1d):
#             return self.normalizer(input.permute(0, 2, 1)).permute(0, 2, 1)
#         else:
#             assert self.normalizer is None, "Unknown normalizer type"
#             return input

# class MultiHeadAttentionLayer(nn.Sequential):
#     def __init__(self,
#                  n_heads,
#                  embed_dim,
#                  feed_forward_hidden=512,
#                  normalization='batch'):
#         super().__init__(
#             SkipConnection(
#                 MultiHeadAttention(
#                     n_heads,
#                     input_dim=embed_dim,
#                     embed_dim=embed_dim
#                 )
#             ),
#             Normalization(embed_dim, normalization),
#             SkipConnection(
#                 nn.Sequential(
#                     nn.Linear(embed_dim, feed_forward_hidden),
#                     nn.ReLU(),
#                     nn.Linear(feed_forward_hidden, embed_dim)
#                 ) if feed_forward_hidden > 0 else nn.Linear(embed_dim, embed_dim)
#             ),
#             Normalization(embed_dim, normalization)
#         )

# class AMEncoder(nn.Module):
#     def __init__(self,
#                  node_dim,
#                  emb_dim,
#                  n_heads,
#                  n_layers,
#                  normalization='batch',
#                  feed_forward_hidden=512):
#         super().__init__()

#         # To map input to embedding space
#         self.init_embed = nn.Linear(node_dim, emb_dim)
        
#         self.layers = nn.Sequential(*(
#             MultiHeadAttentionLayer(n_heads, emb_dim, feed_forward_hidden, normalization)
#             for _ in range(n_layers)
#         ))

#     def forward(self, x):
#         # Batch multiply to get initial embeddings of nodes
#         h = self.init_embed(x.view(-1, x.size(-1))).view(*x.size()[:2], -1)
#         h = self.layers(h)
#         return h


--------------------------------------------------------------------------------
文件路径: /Users/dxk/Downloads/evrp-eps-main/models/tsn/tsn.py
--------------------------------------------------------------------------------

LARGE_VALUE = int(1e+6)
BIT_LARGE_VALUE = int(1e+4)

import os
import matplotlib.pyplot as plt
import collections
import math
import numpy as np
import torch
from scipy.spatial import distance
from ortools.sat.python import cp_model
from typing import List, Any, Tuple, Union

INFINITY = int(1e+14)

class TimeSpaceNetwork():
    def __init__(self, 
                 num_nodes: int,
                 T: int,
                 dt: float,
                 veh_speed: int,
                 distance_matrix: int,
                 max_traversal_step: int = 1) -> None:
        self.num_nodes = num_nodes
        self.T = T
        self.veh_speed = veh_speed
        self.distance_matrix = distance_matrix
        # 0 -> invalid, 1 -> valid
        self.valid_nodes = np.ones((num_nodes, T)) # all nodes are valid here
        self.valid_arcs  = np.zeros((num_nodes, num_nodes, T, T), dtype='int16')
        # remove arcs that cannot be reached within the time (traversal_steps * dt)
        for t1 in range(T):
            for t2 in range(t1+1, T):
                self.valid_arcs[:, :, t1, t2] = (distance_matrix <= veh_speed * (t2 - t1) * dt)
        # remove arcs that traversal more than (max_traversal_step+1) steps:
        # EVs alway reach a node at the earliest
        for t1 in range(T):
            for t2 in range(t1+1, T-max_traversal_step):
                for t3 in range(t2+max_traversal_step, T):
                    self.valid_arcs[:, :, t1, t3] = np.maximum(self.valid_arcs[:, :, t1, t3] - self.valid_arcs[:, :, t1, t2], 0)
        # remove duplicated stay arcs:
        # stay arcs that traverse more than 2 steps is not needed as it can be represented by two stay arcs that traverse only 1 step instead
        for t1 in range(T):
            for t2 in range(t1+2, T):
                np.fill_diagonal(self.valid_arcs[:, :, t1, t2], 0)

        # store valid nodes & arcs
        self.nodes = [(node_id, t) for node_id, t in zip(*np.where(self.valid_nodes))]
        self.arcs = [(from_node_id, to_node_id, from_time, to_time) for from_node_id, to_node_id, from_time, to_time in zip(*np.where(self.valid_arcs))]

    def inflow_arcs(self, to_node_id: int, to_t: int) -> List[Tuple[int, int, int, int]]:
        from_nodes = np.where(self.valid_arcs[:, to_node_id, :, to_t])
        inflows = [(from_node_id, to_node_id, from_t, to_t) for from_node_id, from_t in zip(*from_nodes)]
        return inflows

    def outflow_arcs(self, from_node_id: int, from_t: int) -> List[Tuple[int, int, int, int]]:
        to_nodes = np.where(self.valid_arcs[from_node_id, :, from_t, :])
        outflows = [(from_node_id, to_node_id, from_t, to_t) for to_node_id, to_t in zip(*to_nodes)]
        return outflows

    def stay_arcs(self, to_node_id: int, to_t: int) -> Union[Tuple[int, int, int, int], None]:
        if to_t > 0:
            return (to_node_id, to_node_id, to_t-1, to_t)
        else:
            return None

    def arriving_arcs(self, arriving_time: int) -> List[Tuple[int, int, int, int]]:
        from_nodes = np.where(self.valid_arcs[:, :, :, arriving_time])
        arrivings = [(from_id, to_id, from_time, arriving_time) for from_id, to_id, from_time in zip(*from_nodes)]
        return arrivings

    def time_slice(self, t: int) -> List[Tuple[int, int]]:
        return [(id[0], t) for id in zip(*np.where(self.valid_nodes[:, t]))]

    def arc_distance(self, arc: Tuple[int, int, int, int]) -> int:
        return self.distance_matrix[arc[0]][arc[1]]

    # def disp(self):
    #     print(self.nodes)
    #     print(self.distance_matrix)
    #     #print(self.arcs_array)
    #     block = np.block([[self.valid_arcs[t1, t2] for t2 in self.time_index] for t1 in self.time_index])
    #     print(block)

    def visualize(self, outputdir: str) -> None:
        pass
        os.makedirs(outputdir, exist_ok=True)
        # DEBUG用 arc, nodeの可視化
        self.plot_node_arc(self.nodes, self.arcs, outputdir)
        #self.plot_node_arc(self.time_slice(1), [])
        #self.plot_node_arc([], self.inflow_arcs(2, 1))
        #self.plot_node_arc([], self.outflow_arcs(1, 1))
        #self.plot_node_arc([], self.stay_arcs(2,1))

    def plot_node_arc(self, 
                      nodes: List[Tuple[int, int]], 
                      arcs: List[Tuple[int, int, int, int]], 
                      outputdir: str = None) -> None:
        fig = plt.figure(figsize=(30, 24))
        ax = fig.add_subplot()
        for node in nodes:
            ax.scatter(node[1], node[0], s=128, color='red')
        for arc in arcs:
            ax.annotate("", xy=[arc[3], arc[1]], xytext=[arc[2], arc[0]],
                        arrowprops=dict(shrink=0, width=0.2, headwidth=8, headlength=6, connectionstyle='arc3',
                                        facecolor='gray', edgecolor='gray', alpha=0.4))
        # ax.set_xticks(self.T)
        # ax.set_yticks(range(0, len(self.distance_matrix)))
        # ax.set_xlim(self.time_index[0], self.time_index[-1])
        # ax.set_ylim(-len(self.distance_matrix)*0.05, (len(self.distance_matrix)-1)*1.05)
        if outputdir is None:
            plt.show()
        else:
            plt.savefig(os.path.join(outputdir, 'TSN.png'))

def flatten_list(l: list) -> List[Any]:
    for el in l:
        if isinstance(el, collections.abc.Iterable) and not isinstance(el, (str, bytes)):
            yield from flatten_list(el)
        else:
            yield el

class VarArraySolutionPrinterWithLimit(cp_model.CpSolverSolutionCallback):
    def __init__(self, variables, limit) -> None:
        cp_model.CpSolverSolutionCallback.__init__(self)
        self.__variables = variables
        self.__solution_count = 0
        self.__solution_limit = limit

    def on_solution_callback(self):
        self.__solution_count += 1
        # for v in self.__variables:
        #     print(f'{v}={self.Value(v)}')
        # print()
        if self.__solution_count >= self.__solution_limit:
            print(f'Stop search after {self.__solution_limit} solutions')
            self.StopSearch()

    def solution_count(self):
        return self.__solution_count

class CP4TSN():
    def __init__(self,
                 time_horizon: int = 12,
                 dt: float = 0.5,
                 vehicle_speed: float = 41,
                 loss_coef: int = 1000,
                 loc_pre_time: float = 0.5,
                 loc_post_time: float = 0.5,
                 depot_pre_time: float = 0.17,
                 depot_post_time: float = 0.17,
                 ensure_minimum_charge: bool = True,
                 ensure_minimum_supply: bool = True,
                 random_seed: int = 1234,
                 num_search_workers: int = 4,
                 log_search_progress: bool = False,
                 limit_type: str = None,
                 time_limit: float = 60.0,
                 solution_limit: int = 10):
        """
        Parameters
        ----------

        """
        self.time_horizon = time_horizon
        self.dt = dt
        self.T  = int(time_horizon / dt) + 1
        self.vehicle_speed = vehicle_speed
        self.loss_coef = loss_coef
        self.loc_pre_time = loc_pre_time
        self.loc_post_time = loc_post_time
        self.depot_pre_time = depot_pre_time
        self.depot_post_time = depot_post_time
        self.ensure_minimum_charge = ensure_minimum_charge
        self.ensure_minimum_supply = ensure_minimum_supply
        self.loc_surplus_pre_time = loc_pre_time - dt * (math.ceil(loc_pre_time / dt) - 1)
        self.loc_surplus_post_time = loc_post_time - dt * (math.ceil(loc_post_time / dt) - 1)
        self.depot_surplus_pre_time = depot_pre_time - dt * (math.ceil(depot_pre_time / dt) - 1)
        self.depot_surplus_post_time = depot_post_time - dt * (math.ceil(depot_post_time / dt) - 1)

        self.random_seed = random_seed
        self.num_search_workers = num_search_workers
        self.log_search_progress = log_search_progress
        self.limit_type = limit_type
        # NOTE: time_limit could make the results unrepreducible even if random_seed is set 
        # because the calculation time could differ in each run, resulting in different numbers of found solution
        self.time_limit = time_limit
        self.solution_limit = solution_limit

    def solve(self, input: dict, log_fname: str = None):
        """
        Paramters
        ---------

        Returns
        -------

        """
        # convert input feature
        self.set_input(input)

        # deffine Time Space Network
        self.tsn = TimeSpaceNetwork(self.num_nodes, self.T, self.dt, self.normalized_veh_speed, self.distance_matrix)

        # define a model
        print("defining a model...", end="")
        model = cp_model.CpModel()
        variables = self.add_variables(model)
        self.add_constraints(model, variables)
        self.add_objectives(model, variables, self.loss_coef)
        print("done")

        # validate the model
        validate_res = model.Validate()
        if validate_res != "":
            print(validate_res)

        # solve TSN with the CP-SAT solver
        solver = cp_model.CpSolver()
        solver.parameters.random_seed = self.random_seed
        solver.parameters.num_search_workers = self.num_search_workers
        solver.log_search_progress = self.log_search_progress
        if self.limit_type == "time":
            solver.parameters.max_time_in_seconds = self.time_limit
            status = solver.Solve(model)
        elif self.limit_type == "solution_count":
            solver.parameters.num_search_workers = 1 # enumerating all solutions does not work in parallel
            solver.parameters.enumerate_all_solutions = True
            variable_list = []
            for variable in variables.values():
                if isinstance(variable, list):
                    variable_list += list(flatten_list(variable))
                elif isinstance(variable, dict):
                    variable_list += list(variable.values())
                else:
                    variable_list += [variable]
            solution_printer = VarArraySolutionPrinterWithLimit(variable_list, self.solution_limit)
            status = solver.Solve(model, solution_printer)
        else:
            status = solver.Solve(model)
        
        if status == cp_model.OPTIMAL:
            print("The optimal solution found!!!")
        elif status == cp_model.FEASIBLE:
            print("A feasible solution found!")
        else:
            print("No solution found :(")

        # if status in [cp_model.OPTIMAL, cp_model.FEASIBLE]:
        #     print([solver.Value(variables["num_down_loc"][t]) for t in range(self.T)])
        #     print([solver.Value(variables["travel_distance"][veh_id]) for veh_id in range(self.num_vehicles)])
        #     for veh_id in range(self.num_vehicles):
        #         print(f"EV{veh_id}")
        #         route = [arc for arc in self.tsn.arcs if solver.Value(variables["x"][veh_id, arc]) == 1]
        #         route.sort(key=lambda a: a[2])
        #         for arc in route:
        #             print(f"(time:{arc[2]}->{arc[3]}) station:{arc[0]}-> {arc[1]}")
        #     print(solver.Value(variables["loss1"]) / (LARGE_VALUE * BIT_LARGE_VALUE), solver.Value(variables["loss2"]) / (LARGE_VALUE * BIT_LARGE_VALUE))
        # print(f"Status: {solver.StatusName(status)}")
        # print(solver.SolutionInfo())
        # print(solver.ResponseStats())
        
        route = [[] for _ in range(self.num_vehicles)]
        for veh_id in range(self.num_vehicles):
            arcs = [arc for arc in self.tsn.arcs if solver.Value(variables["x"][veh_id, arc]) == 1]
            arcs.sort(key=lambda a: a[2])
            for arc in arcs:
                route[veh_id].append((arc[2], arc[3], arc[0], arc[1]))
        return {
            "route": route,
            "total_route_length": sum(solver.Value(variables["travel_distance"][veh_id]) for veh_id in range(self.num_vehicles)) / LARGE_VALUE,
            "num_down_locs": [solver.Value(variables["num_down_loc"][t]) for t in range(self.T)],
            "objective_value": solver.ObjectiveValue() / (LARGE_VALUE * BIT_LARGE_VALUE)
        }
    
    def set_input(self, input: dict):
        # locations
        self.loc_cap = (input["loc_cap"] * LARGE_VALUE).to(torch.long).tolist() # [num_locs]
        self.loc_consump_rate = (input["loc_consump_rate"] * LARGE_VALUE).to(torch.long).tolist() # [num_locs]
        self.loc_init_batt = (input["loc_cap"] * LARGE_VALUE).to(torch.long).tolist() # [num_locs]
        self.loc_min_batt = 0

        # depots
        self.depot_discharge_rate = (input["depot_discharge_rate"] * LARGE_VALUE).to(torch.long).tolist() # [num_depots]
        
        # EVs
        self.veh_cap = (input["vehicle_cap"] * LARGE_VALUE).to(torch.long).tolist() # [num_vehicles]
        self.veh_init_batt = (input["vehicle_cap"] * LARGE_VALUE).to(torch.long).tolist() # [num_vehicles]
        self.veh_discharge_rate = (input["vehicle_discharge_rate"] * LARGE_VALUE).to(torch.long).tolist()
        self.veh_consump_rate = input["vehicle_consump_rate"].tolist()
        self.veh_init_position_id = input["vehicle_initial_position_id"].tolist() # [num_vehicles]
        self.veh_min_batt = 0

        # distance_matrix
        self.loc_coords = input["loc_coords"].detach().numpy().copy() # [num_locs, coord_dim]
        self.depot_coords = input["depot_coords"].detach().numpy().copy() # [num_depots, coord_dim]
        self.node_coords = np.concatenate((self.loc_coords, self.depot_coords), 0) # [num_nodes, coord_dim]
        self.distance_matrix = (distance.cdist(self.node_coords, self.node_coords) * LARGE_VALUE).astype(np.long)

        # parameters
        self.num_locs = len(self.loc_cap)
        self.num_depots = len(self.depot_discharge_rate)
        self.num_nodes = self.num_locs + self.num_depots
        self.num_vehicles = len(self.veh_cap)
        self.grid_scale = input["grid_scale"]
        self.normalized_veh_speed = int(self.vehicle_speed / self.grid_scale * LARGE_VALUE)

    def add_variables(self, model):
        """
        Parameters
        ----------

        Returns
        -------
        """
        variables = {}
        self.add_batt_variables(model, variables)
        self.add_route_variables(model, variables)
        self.add_objective_variables(model, variables)
        return variables

    def add_batt_variables(self, model, var):
        # for locations
        var["loc_batt"] = [[model.NewIntVar(0, self.loc_cap[i], f"loc{i}_t{t}_batt") for t in range(self.T)] for i in range(self.num_locs)]
        var["loc_slack"] = [[model.NewIntVar(0, self.loc_min_batt+1, f"loc{i}_t{t}_slack") for t in range(self.T)] for i in range(self.num_locs)]
        var["enable_slack"] = [[model.NewBoolVar(f"loc{i}_t{t}_enable_slack") for t in range(self.T)] for i in range(self.num_locs)]
        var["loc_is_down"] = [[model.NewBoolVar(f"loc{i}_t{t}_is_down") for t in range(self.T)] for i in range(self.num_locs)]
        var["loc_is_full"] = [[model.NewBoolVar(f"loc{i}_t{t}_is_full") for t in range(self.T)] for i in range(self.num_locs)]
        var["loc_is_normal"] = [[model.NewBoolVar(f"loc{i}_t{t}_is_normal") for t in range(self.T)] for i in range(self.num_locs)]
        var["loc_charge_amount"] = [[model.NewIntVar(0, self.loc_cap[i], f"loc{i}_t{t}_charge_amount") for t in range(self.T)] for i in range(self.num_locs)]
        # for EVs
        var["veh_batt"]           = [[model.NewIntVar(0, self.veh_cap[k], f"veh{k}_t{t}_batt") for t in range(self.T)] for k in range(self.num_vehicles)]
        var["veh_charge_amount"]  = [[model.NewIntVar(0, self.veh_cap[k], f"veh{k}_t{t}_charge_amount") for t in range(self.T)] for k in range(self.num_vehicles)]
        var["veh_is_discharging"] = [[model.NewBoolVar(f"veh{k}_t{t}_is_charging") for t in range(self.T)] for k in range(self.num_vehicles)]

    def add_route_variables(self, model, var):
        var["x"] = {(k, arc): model.NewBoolVar(f"x_veh{k}_arc{arc}") for k in range(self.num_vehicles) for arc in self.tsn.arcs}
        var["z"] = [[[model.NewBoolVar(f"z_veh{k}_node{n}_t{t}") for t in range(self.T)] for n in range(self.num_nodes)] for k in range(self.num_vehicles)]
        var["loc_is_down2"] = [[model.NewBoolVar(f"loc{i}_t{t}_is_down2") for t in range(self.T)] for i in range(self.num_locs)]
        var["veh_prepare_at_loc"]  = [[[model.NewBoolVar(f"veh{k}_loc{i}_t{t}_prepare_at_loc") for t in range(self.T)] for i in range(self.num_locs)] for k in range(self.num_vehicles)]
        var["veh_prepare_at_loc2"] = [[[model.NewBoolVar(f"veh{k}_loc{i}_t{t}_prepare_at_loc2") for t in range(self.T)] for i in range(self.num_locs)] for k in range(self.num_vehicles)] 
        var["veh_cleanup_at_loc"]  = [[[model.NewBoolVar(f"veh{k}_loc{i}_t{t}_cleanup_at_loc") for t in range(self.T)] for i in range(self.num_locs)] for k in range(self.num_vehicles)]
        var["veh_cleanup_at_loc2"] = [[[model.NewBoolVar(f"veh{k}_loc{i}_t{t}_cleanup_at_loc2") for t in range(self.T)] for i in range(self.num_locs)] for k in range(self.num_vehicles)]
        var["veh_prepare_at_depot"] = [[[model.NewBoolVar(f"veh{k}_depot{j}_t{t}_prepare_at_depot") for t in range(self.T)] for j in range(self.num_depots)] for k in range(self.num_vehicles)]
        var["veh_cleanup_at_depot"] = [[[model.NewBoolVar(f"veh{k}_depot{j}_t{t}_cleanup_at_depot") for t in range(self.T)] for j in range(self.num_depots)] for k in range(self.num_vehicles)]
        if self.ensure_minimum_supply:
            var["loc_supply_notenough"] = [[[model.NewBoolVar(f"not_enough_veh{k}_loc{i}_t{t}") for t in range(self.T)] for i in range(self.num_locs)] for k in range(self.num_vehicles)]
            var["loc_suuply_notenough_notcleanup"] = [[[model.NewBoolVar(f"notenough_notcleanup_veh{k}_loc{i}_t{t}") for t in range(self.T)] for i in range(self.num_locs)] for k in range(self.num_vehicles)]
        if self.ensure_minimum_charge:
            var["veh_charge_notenough"] = [[[model.NewBoolVar(f"not_enough_veh{k}_depot{j}_t{t}") for t in range(self.T)] for j in range(self.num_depots)] for k in range(self.num_vehicles)]
            var["veh_charge_notenough_notcleanup"] = [[[model.NewBoolVar(f"notenough_notcleanup_veh{k}_depot{j}_t{t}") for t in range(self.T)] for j in range(self.num_depots)] for k in range(self.num_vehicles)]

    def add_objective_variables(self, model, var):
        var["num_down_loc"] = [model.NewIntVar(0, self.num_locs, f"num_down_loc_t{t}") for t in range(self.T)]
        var["travel_distance"] = [model.NewIntVar(0, INFINITY, f"veh{k}_travel_distance") for k in range(self.num_vehicles)]
        var["loss1"] = model.NewIntVar(0, INFINITY, "loss1")
        var["loss2"] = model.NewIntVar(0, INFINITY, "loss2")

    def add_constraints(self, model, var):
        self.battery_init_lowerbound(model, var)
        self.ensure_route_continuity(model, var)
        self.forbit_multi_veh_at_same_node(model, var)
        self.define_batt_behavior(model, var)
        self.add_objective_constraints(model, var)

    def battery_init_lowerbound(self, model, var):
        # for EVs
        for veh_id in range(self.num_vehicles):
            model.Add(var["veh_batt"][veh_id][0] == self.veh_init_batt[veh_id])
            for t in range(self.T):
                model.Add(var["veh_is_discharging"][veh_id][t] == sum(var["z"][veh_id][loc_id][t] for loc_id in range(self.num_locs)))
                model.Add(var["veh_batt"][veh_id][t] >= self.veh_min_batt).OnlyEnforceIf(var["veh_is_discharging"][veh_id][t])
        # for locations
        for loc_id in range(self.num_locs):
            model.Add(var["loc_batt"][loc_id][0] == self.loc_init_batt[loc_id])
            for t in range(self.T):
                # implement enable_slack
                model.Add(var["loc_batt"][loc_id][t] < self.loc_min_batt).OnlyEnforceIf(var["enable_slack"][loc_id][t])
                model.Add(var["loc_batt"][loc_id][t] >= self.loc_min_batt).OnlyEnforceIf(var["enable_slack"][loc_id][t].Not())
                # implement loc_slack
                model.Add(var["loc_slack"][loc_id][t] >= 1).OnlyEnforceIf(var["enable_slack"][loc_id][t])
                model.Add(var["loc_slack"][loc_id][t] == 0).OnlyEnforceIf(var["enable_slack"][loc_id][t].Not())
                # add a constraint
                model.Add(var["loc_batt"][loc_id][t] + var["loc_slack"][loc_id][t] >= self.loc_min_batt)

    def ensure_route_continuity(self, model, var):
        """
        Parameters
        ----------

        """
        for veh_id in range(self.num_vehicles):
            # set initial position 
            # outflow arcs of the first node for a vehcile is 1
            outflow_arcs_from_init_depot = self.tsn.outflow_arcs(self.veh_init_position_id[veh_id], 0)
            model.Add(sum(var["x"][veh_id, arc] for arc in outflow_arcs_from_init_depot) == 1)
            
            # 
            for node_id in range(self.num_nodes):
                if node_id in self.veh_init_position_id:
                    continue
                outflow_arcs = self.tsn.outflow_arcs(node_id, 0)
                for arc in outflow_arcs:
                    model.Add(var["x"][veh_id, arc] == 0)

            # route continuity: the number outflow arcs shold equals to the number of inflow arcs in a node
            # To handle sparsified TSN, we use get_xxx_arcs function
            for t in range(1, self.T-1):
                for n in range(self.num_nodes):
                    inflow_arcs  = self.tsn.inflow_arcs(n, t)  # get valid inflow arcs
                    outflow_arcs = self.tsn.outflow_arcs(n, t) # get valid outflow arcs
                    model.Add(sum(var["x"][veh_id, arc] for arc in inflow_arcs) == sum(var["x"][veh_id, arc] for arc in outflow_arcs))

            # 
            for t in range(0, self.T):
                for n in range(self.num_nodes):
                    if t == 0:
                        model.Add(var["z"][veh_id][n][t] == 0)
                    else:
                        stay_arc = self.tsn.stay_arcs(n, t) # get stay arc
                        if stay_arc is not None:
                            model.Add(var["z"][veh_id][n][t] <= var["x"][veh_id, stay_arc])

    def forbit_multi_veh_at_same_node(self, model, var):
        for t in range(1, self.T):
            for n in range(self.num_nodes):
                inflow_arcs = self.tsn.inflow_arcs(n, t)
                model.Add(sum(var["x"][veh_id, arc] for arc in inflow_arcs for veh_id in range(self.num_vehicles)) <= 1)
  
    def define_batt_behavior(self, model, var):
        prepare_t = math.ceil(self.loc_pre_time / self.dt)
        for loc_id in range(self.num_locs):
            for veh_id in range(self.num_vehicles):
                for p in range(prepare_t):
                    model.Add(var["veh_prepare_at_loc"][veh_id][loc_id][p] == 0)
                    model.Add(var["veh_cleanup_at_loc"][veh_id][loc_id][self.T-p-1] == 0)
                model.Add(var["veh_prepare_at_loc2"][veh_id][loc_id][self.T-1] == 0)
                model.Add(var["veh_cleanup_at_loc2"][veh_id][loc_id][0] == 0)

        for t in range(self.T-1):
            prev_t = t
            curr_t = t + 1
            # for EVs
            arriving_arcs = self.tsn.arriving_arcs(curr_t)
            for veh_id in range(self.num_vehicles):
                # charging: depot -> vehcile
                model.Add(var["veh_charge_amount"][veh_id][curr_t] == sum([int(self.depot_discharge_rate[depot_offst_id] * self.dt) * var["z"][veh_id][depot_id][curr_t] for depot_offst_id, depot_id in enumerate(range(self.num_locs, self.num_nodes))])
                          - sum(int(self.veh_discharge_rate[veh_id] * self.depot_surplus_pre_time) * var["veh_prepare_at_depot"][veh_id][depot_offst_id][curr_t] for depot_offst_id in range(self.num_depots))   # TODO
                          - sum(int(self.veh_discharge_rate[veh_id] * self.depot_surplus_post_time) * var["veh_cleanup_at_depot"][veh_id][depot_offst_id][curr_t] for depot_offst_id in range(self.num_depots))) # TODO
                # EV's battery change
                model.Add(var["veh_batt"][veh_id][curr_t] == var["veh_batt"][veh_id][prev_t] 
                          - sum([int(self.veh_discharge_rate[veh_id] * self.dt) * var["z"][veh_id][i][curr_t] for i in range(self.num_locs)]) # discharge consumption 
                          - sum([int(self.veh_consump_rate[veh_id] * self.tsn.arc_distance(arc)) * var["x"][veh_id, arc] for arc in arriving_arcs])              # travel consumption
                          + var["veh_charge_amount"][veh_id][curr_t])                                                     # power charge form a charge station 
            
            # for locations
            for loc_id in range(self.num_locs):
                for veh_id in range(self.num_vehicles):
                    if prev_t + prepare_t < self.T: # if prepare time does not exceed the time horizon
                        # implement veh_prepare_at_loc & veh_cleanup_at_loc
                        diff_z_loc = var["z"][veh_id][loc_id][prev_t+prepare_t] - var["z"][veh_id][loc_id][prev_t]
                        model.Add(diff_z_loc == 1).OnlyEnforceIf(var["veh_prepare_at_loc"][veh_id][loc_id][prev_t+prepare_t])
                        model.Add(diff_z_loc <= 0).OnlyEnforceIf(var["veh_prepare_at_loc"][veh_id][loc_id][prev_t+prepare_t].Not())
                        model.Add(-diff_z_loc == 1).OnlyEnforceIf(var["veh_cleanup_at_loc"][veh_id][loc_id][prev_t])
                        model.Add(-diff_z_loc <= 0).OnlyEnforceIf(var["veh_cleanup_at_loc"][veh_id][loc_id][prev_t].Not())
                    # implement veh_prepare_at_loc & veh_cleanup_at_loc
                    diff_veh_prepare_at_loc = var["veh_prepare_at_loc"][veh_id][loc_id][prev_t] - var["veh_prepare_at_loc"][veh_id][loc_id][curr_t]
                    diff_veh_cleanup_at_loc = var["veh_cleanup_at_loc"][veh_id][loc_id][curr_t] - var["veh_cleanup_at_loc"][veh_id][loc_id][prev_t]
                    model.Add(diff_veh_prepare_at_loc == 1).OnlyEnforceIf(var["veh_prepare_at_loc2"][veh_id][loc_id][prev_t])
                    model.Add(diff_veh_prepare_at_loc <= 0).OnlyEnforceIf(var["veh_prepare_at_loc2"][veh_id][loc_id][prev_t].Not())
                    model.Add(diff_veh_cleanup_at_loc == 1).OnlyEnforceIf(var["veh_cleanup_at_loc2"][veh_id][loc_id][curr_t])
                    model.Add(diff_veh_cleanup_at_loc <= 0).OnlyEnforceIf(var["veh_cleanup_at_loc2"][veh_id][loc_id][curr_t].Not())
                if self.ensure_minimum_supply:
                    for veh_id in range(self.num_vehicles):
                        # implement loc_supply_not_enough
                        model.Add(self.loc_cap[loc_id] - var["loc_batt"][loc_id][prev_t] >  0).OnlyEnforceIf(var["loc_supply_notenough"][veh_id][loc_id][prev_t])
                        model.Add(self.loc_cap[loc_id] - var["loc_batt"][loc_id][prev_t] <= 0).OnlyEnforceIf(var["loc_supply_notenough"][veh_id][loc_id][prev_t].Not())
                        # implement loc_suuply_notenough_notcleanup
                        model.AddImplication(var["loc_suuply_notenough_notcleanup"][veh_id][loc_id][prev_t], var["loc_supply_notenough"][veh_id][loc_id][prev_t])
                        model.AddImplication(var["loc_suuply_notenough_notcleanup"][veh_id][loc_id][prev_t], var["veh_cleanup_at_loc"][veh_id][loc_id][prev_t].Not())
                        # add a constraint
                        model.Add(var["z"][veh_id][loc_id][curr_t] >= var["z"][veh_id][loc_id][prev_t]).OnlyEnforceIf(var["loc_suuply_notenough_notcleanup"][veh_id][loc_id][prev_t])

                # supplying: 
                model.Add(var["loc_charge_amount"][loc_id][curr_t] == int(self.veh_discharge_rate[veh_id] * self.dt) * sum([var["z"][veh_id_][loc_id][curr_t] - var["veh_prepare_at_loc"][veh_id_][loc_id][curr_t] - var["veh_cleanup_at_loc"][veh_id_][loc_id][curr_t] for veh_id_ in range(self.num_vehicles)])
                                                                      + int(self.veh_discharge_rate[veh_id] * (self.dt - self.loc_surplus_pre_time)) * sum(var["veh_prepare_at_loc2"][veh_id_][loc_id][curr_t] for veh_id_ in range(self.num_vehicles))
                                                                      + int(self.veh_discharge_rate[veh_id] * (self.dt - self.loc_surplus_post_time)) * sum(var["veh_cleanup_at_loc2"][veh_id_][loc_id][curr_t] for veh_id_ in range(self.num_vehicles)))
                # location's battery change
                model.Add(var["loc_batt"][loc_id][curr_t] == var["loc_batt"][loc_id][prev_t]
                            - (1 - var["loc_is_down"][loc_id][curr_t]) * int(self.loc_consump_rate[loc_id] * self.dt)
                            + var["loc_charge_amount"][loc_id][curr_t]
                            ).OnlyEnforceIf(var["loc_is_normal"][loc_id][curr_t])
                
                # clippling battery
                # implement loc_is_down & loc_is_full
                loc_curr_batt = var["loc_batt"][loc_id][prev_t] - int(self.loc_consump_rate[loc_id] * self.dt) + var["loc_charge_amount"][loc_id][curr_t]
                model.Add(loc_curr_batt <= 0).OnlyEnforceIf(var["loc_is_down"][loc_id][curr_t])
                model.Add(loc_curr_batt >  0).OnlyEnforceIf(var["loc_is_down"][loc_id][curr_t].Not())
                model.Add(loc_curr_batt >= self.loc_cap[loc_id]).OnlyEnforceIf(var["loc_is_full"][loc_id][curr_t])
                model.Add(loc_curr_batt <  self.loc_cap[loc_id]).OnlyEnforceIf(var["loc_is_full"][loc_id][curr_t].Not())
                # clip battery
                model.Add(var["loc_batt"][loc_id][curr_t] == 0).OnlyEnforceIf(var["loc_is_down"][loc_id][curr_t])
                model.Add(var["loc_batt"][loc_id][curr_t] == self.loc_cap[loc_id]).OnlyEnforceIf(var["loc_is_full"][loc_id][curr_t])

            # for depots
            for depot_offst_id, depot_id in enumerate(range(self.num_locs, self.num_nodes)):
                for veh_id in range(self.num_vehicles):
                    # implement veh_prepare_at_depot & veh_cleanup_at_depot
                    diff_z_depot = var["z"][veh_id][depot_id][curr_t] - var["z"][veh_id][depot_id][prev_t]
                    model.Add(diff_z_depot == 1).OnlyEnforceIf(var["veh_prepare_at_depot"][veh_id][depot_offst_id][curr_t])
                    model.Add(diff_z_depot <= 0).OnlyEnforceIf(var["veh_prepare_at_depot"][veh_id][depot_offst_id][curr_t].Not())
                    model.Add(-diff_z_depot == 1).OnlyEnforceIf(var["veh_cleanup_at_depot"][veh_id][depot_offst_id][prev_t])
                    model.Add(-diff_z_depot <= 0).OnlyEnforceIf(var["veh_cleanup_at_depot"][veh_id][depot_offst_id][prev_t].Not())
                if self.ensure_minimum_charge:
                    for veh_id in range(self.num_vehicles):
                        # implement veh_charge_notenough
                        model.Add(self.veh_cap[veh_id] - var["veh_batt"][veh_id][prev_t] >  0).OnlyEnforceIf(var["veh_charge_notenough"][veh_id][depot_offst_id][prev_t])
                        model.Add(self.veh_cap[veh_id] - var["veh_batt"][veh_id][prev_t] <= 0).OnlyEnforceIf(var["veh_charge_notenough"][veh_id][depot_offst_id][prev_t].Not())
                        # implement 
                        model.AddImplication(var["veh_charge_notenough_notcleanup"][veh_id][depot_offst_id][prev_t], var["veh_charge_notenough"][veh_id][depot_offst_id][prev_t])
                        model.AddImplication(var["veh_charge_notenough_notcleanup"][veh_id][depot_offst_id][prev_t], var["veh_cleanup_at_depot"][veh_id][depot_offst_id][prev_t].Not())
                        # add a constraint
                        model.Add(var["z"][veh_id][depot_id][curr_t] >= var["z"][veh_id][depot_id][prev_t]).OnlyEnforceIf(var["veh_charge_notenough_notcleanup"][veh_id][depot_offst_id][prev_t])

        for t in range(self.T):
            for loc_id in range(self.num_locs):
                model.AddBoolOr([var["loc_is_down"][loc_id][t], var["loc_is_full"][loc_id][t], var["loc_is_normal"][loc_id][t]]) # the sate of a location is down or ful or normal
                model.Add(var["loc_batt"][loc_id][t] <= 0).OnlyEnforceIf(var["loc_is_down2"][loc_id][t])
                model.Add(var["loc_batt"][loc_id][t] >= 1).OnlyEnforceIf(var["loc_is_down2"][loc_id][t].Not())

    def add_objective_constraints(self, model, var):
        # calculate the number of downed locations at each step
        for t in range(self.T):
            model.Add(var["num_down_loc"][t] == sum(var["loc_is_down2"][loc_id_][t] for loc_id_ in range(self.num_locs)))
        # calculate the total travel distance of each EV
        for veh_id in range(self.num_vehicles):
            model.Add(var["travel_distance"][veh_id] == sum(var["x"][veh_id, arc] * self.tsn.arc_distance(arc) for arc in self.tsn.arcs))

    def add_objectives(self, 
                       model, 
                       var: dict, 
                       loss_coef: int):
        # for travel distance
        avg_travel_distance = sum(var["travel_distance"][veh_id] for veh_id in range(self.num_vehicles)) * int(BIT_LARGE_VALUE / self.num_vehicles)
        # for downed locs
        down_rate = sum(var["num_down_loc"][t] for t in range(self.T)) * int(LARGE_VALUE / (self.num_locs * self.T)) * BIT_LARGE_VALUE
        model.Add(var["loss1"] == avg_travel_distance)
        model.Add(var["loss2"] == loss_coef * down_rate)
        # define objectives
        model.Minimize(avg_travel_distance + loss_coef * down_rate)


--------------------------------------------------------------------------------
文件路径: /Users/dxk/Downloads/evrp-eps-main/models/tsn/clustered_tsn.py
--------------------------------------------------------------------------------

import time
import json
import pickle
import os
import math
import numpy as np
import torch
import torch.nn as nn
from typing import Dict
from models.tsn.tsn import CP4TSN, LARGE_VALUE
from multiprocessing import Pool
from sklearn.cluster import KMeans
from scipy.spatial.distance import cdist
from scipy.optimize import linear_sum_assignment
from ortools.sat.python import cp_model

class ClusteringBase(nn.Module):
    def __init__(self, merge_duplicated_depots: bool = False) -> None:
        super().__init__()
        self.merge_duplicated_depots = merge_duplicated_depots
    
    def forward(self, input: Dict[str, torch.tensor]) -> tuple:
        """
        Parameters
        ----------
        input: dict of torch.tensor

        Returns
        -------
        div_input: list of dict of torch.tensor
        """
        num_locs     = len(input["loc_coords"])
        veh_init_postion_id = input["vehicle_initial_position_id"]
        num_vehicles = len(veh_init_postion_id)
        num_clusters = num_vehicles
        unique_pos_ids = torch.unique(veh_init_postion_id)

        # clustering
        div_loc_id_tmp, div_depot_id_tmp = self.clustering(input, num_clusters, unique_pos_ids)

        # merge clusters that have the same initial depot (veh_init_position_id)
        if self.merge_duplicated_depots:
            div_loc_id = []
            div_depot_id = []
            div_veh_id = []
            for unique_pos_id in unique_pos_ids:
                merge_indicies = torch.where(veh_init_postion_id == unique_pos_id)[0]
                div_loc_id.append(torch.cat([div_loc_id_tmp[merge_idx.item()] for merge_idx in merge_indicies]))
                merge_depot_id_list = [div_depot_id_tmp[merge_idx.item()] for merge_idx in merge_indicies if div_depot_id_tmp[merge_idx.item()].size()[0] > 0]
                if len(merge_depot_id_list) > 0:
                    div_depot_id.append(torch.cat([torch.cat(merge_depot_id_list), unique_pos_id[None]]))
                else:
                    div_depot_id.append(merge_depot_id_list[0])
                div_veh_id.append(merge_indicies)
        else:
            div_loc_id = div_loc_id_tmp
            div_depot_id = div_depot_id_tmp
            div_veh_id = [torch.tensor([i]) for i in range(num_vehicles)]

        # split inputs
        div_inputs = []
        for i in range(len(div_veh_id)):
            div_input = {}
            for key, value in input.items():
                if "loc" in key:
                    div_input[key] = value[div_loc_id[i]]
                elif "depot" in key:
                    div_input[key] = value[div_depot_id[i] - num_locs]
                elif "vehicle" in key:
                    if key == "vehicle_initial_position_id":
                        cond = torch.full((len(div_depot_id[i]),), False)
                        depot_ids = value[div_veh_id[i]]
                        for depot_id in depot_ids:
                            cond |= (div_depot_id[i] == depot_id)
                        offst_depot_ids = torch.where(cond)[0]
                        div_input[key] = offst_depot_ids + len(div_loc_id[i])
                    else:
                        div_input[key] = value[div_veh_id[i]]
                else:
                    div_input[key] = value
            div_inputs.append(div_input)

        # print summary
        print(f"The original problem was split into {len(div_inputs)} sub-problem(s)!")
        return div_inputs, div_loc_id, div_depot_id, div_veh_id

    def clustering(self, num_clusters, unique_pos_ids):
        NotImplementedError

class KmeansClustering(ClusteringBase):
    def __init__(self,
                 merge_duplicated_depots: bool,
                 num_clusters: int) -> None: #, random_seed, balancing=True):
        super().__init__(merge_duplicated_depots)
        self.num_clusters = num_clusters
        # self.random_seed = random_seed

    def clustering(self,
                   input: Dict[str, torch.tensor],
                   num_clusters: int,
                   unique_pos_ids: torch.tensor) -> tuple:
        # clustering locs
        loc_coords = input["loc_coords"].cpu().detach().numpy().copy()
        num_locs = len(loc_coords)
        # num_locs < num_culsters is not supported 
        loc_cluster_ids, loc_cluster_centers = self.balanced_kmeans(loc_coords, num_clusters)

        # clustering depots except for depots from which EVs depart
        depot_coords = input["depot_coords"] # .cpu().detach().numpy().copy()
        depot_id = torch.arange(len(depot_coords))
        remove_mask = torch.isin(depot_id, unique_pos_ids-num_locs) # [num_depots]
        clustered_depot_id = depot_id[~remove_mask]
        clustered_depot_coords = depot_coords[~remove_mask].cpu().detach().numpy().copy()
        # len(clustered_depot_coords) < num_culsters is not supported
        depot_cluster_ids, depot_cluster_centers = self.balanced_kmeans(clustered_depot_coords, num_clusters)
        
        # matching
        veh_init_pos_ids = input["vehicle_initial_position_id"]
        veh_init_pos = depot_coords[veh_init_pos_ids-num_locs].cpu().detach().numpy().copy() # [num_clusters(vehicles), dim]
        # match the inital charge station with a cluster of locs
        loc_pairs = self.cluster_matching(veh_init_pos, loc_cluster_centers)
        # match the inital charge station with a cluster of locs
        depot_pairs = self.cluster_matching(veh_init_pos, depot_cluster_centers)
        
        div_loc_id = []; div_depot_id = []
        for cluster_id in range(num_clusters):
            div_loc_id.append(torch.tensor(loc_cluster_ids[loc_pairs[cluster_id][1]]))
            div_depot_id.append(clustered_depot_id[depot_cluster_ids[depot_pairs[cluster_id][1]]] + num_locs)
        return div_loc_id, div_depot_id

    def balanced_kmeans(self, x, num_clusters, max_iters=1000):
        """
        Ref: https://stackoverflow.com/questions/5452576/k-means-algorithm-variation-with-equal-cluster-size

        Parameters
        ----------
        x: torch.tensor [num_points, dim]
        num_clusters: int
        max_iters: int

        Returns
        -------
        cluster_ids: list of torch.tensor [num_clusters, num_clustered_points]
        cluster_centers: np.array [num_clusters, dim]
        """
        cluster_size = math.ceil(len(x) / num_clusters)
        kmeans = KMeans(num_clusters, n_init=10)
        kmeans.fit(x)
        centers = kmeans.cluster_centers_
        who_is = np.tile(np.arange(num_clusters), (cluster_size+1))[:len(x)]
        centers_repeated = centers[who_is]
        distance_matrix = cdist(x, centers_repeated)
        X_assignments = linear_sum_assignment(distance_matrix)[1]
        cluster_ids = who_is[X_assignments]

        clustered_ids = []; cluster_centers = []
        for cluster_id in range(num_clusters):
            clustered_id = np.where(cluster_ids == cluster_id)[0].tolist()
            clustered_ids.append(clustered_id)
            cluster_centers.append(x[clustered_id].mean(0))
        return clustered_ids, np.array(cluster_centers)

    def cluster_matching(self, centers1, centers2):
        """
        Parameters
        ----------
        centers1: np.array [num_clusters, dim]
        centers2: np.array [num_clusters, dim]

        Returns
        pair_list: list of tuple (cluster1_id, cluster2_id)
        -------

        """
        assert len(centers1) == len(centers2)
        num_clusters = len(centers1)
        dist = (cdist(centers1, centers2) * LARGE_VALUE).astype(np.long)
        model = cp_model.CpModel()
        edge = [[model.NewBoolVar(f'e_{i}_{j}') for j in range(num_clusters)] for i in range(num_clusters)]
        for cluster_id in range(num_clusters):
            model.Add(sum(edge[cluster_id][j] for j in range(num_clusters)) == 1)
            model.Add(sum(edge[j][cluster_id] for j in range(num_clusters)) == 1)
        model.Minimize(sum(dist[i, j] * edge[i][j] for i in range(num_clusters) for j in range(num_clusters)))
        solver = cp_model.CpSolver()
        status = solver.Solve(model)
        assert status in [cp_model.OPTIMAL, cp_model.FEASIBLE]
        
        pair_list = []
        for i in range(num_clusters):
            for j in range(num_clusters):
                if solver.Value(edge[i][j]):
                    pair_list.append((i, j))
        assert len(pair_list) == num_clusters
        return pair_list

class RandomClustering(ClusteringBase):
    def __init__(self,
                 merge_duplicated_depots: bool,
                 num_clusters: int) -> None:
        super().__init__(merge_duplicated_depots)
        self.num_clusters = num_clusters

    def clustering(self, input, num_clusters, unique_pos_ids):
        # shuffle & split locs
        num_locs = len(input["loc_coords"])
        suffled_loc_id = torch.randperm(num_locs)
        div_loc_id = []
        st = 0; ed = 0
        for i in range(num_clusters):
            ed = st + (num_locs + i) // num_clusters
            div_loc_id.append(suffled_loc_id[st:ed]) 
            st = ed

        # shuffle & split depots
        div_depot_id = []
        num_depots = len(input["depot_coords"])
        shuffled_depot_id = torch.randperm(num_depots) + num_locs
        shuffled_depot_id = shuffled_depot_id[~torch.isin(shuffled_depot_id, unique_pos_ids)] # remove unique_pos_ids
        num_div_depots = len(shuffled_depot_id) # num_depots - num_clusters
        st = 0; ed = 0
        for i in range(num_clusters):
            ed = st + (num_div_depots + i) // num_clusters
            div_depot_id.append(shuffled_depot_id[st:ed])
            st = ed
        
        return div_loc_id, div_depot_id 

class CP4ClusteredTSN():
    def __init__(self,
                 num_clusters: int,
                 cluster_type: str = "kmeans",
                 merge_duplicated_depots: bool = False,
                 parallel: bool = True,
                 num_cpus: int = 4,
                 *args, **kwargs):
        self.cp4tsn = CP4TSN(*args, **kwargs)
        self.num_division = num_clusters
        self.cluster_type = cluster_type
        if cluster_type == "kmeans":
            self.clustering = KmeansClustering(merge_duplicated_depots, num_clusters)
        elif cluster_type == "random":
            self.clustering = RandomClustering(merge_duplicated_depots, num_clusters)
        else:
            NotImplementedError
        self.parallel = parallel
        self.num_cpus = num_cpus

    def solve(self, input: dict, log_fname: str = None):
        """
        Parameters
        ----------
        input: dict of torch.tensor

        Returns
        -------
        route: list
        route_length: float
        down_rate: float
        objective_value: float
        calc_time: float
        """
        # parameters 
        num_locs = len(input["loc_coords"])
        num_vehicles = len(input["vehicle_cap"])

        # split problem into subproblems
        div_inputs, div_loc_id, div_depot_id, div_veh_id = self.clustering(input)

        # solve sub-problems
        start_time = time.perf_counter()
        if self.parallel:
            with Pool(self.num_cpus) as pool:
                results = list(pool.imap(self.cp4tsn.solve, div_inputs))
        else:
            results = []
            for div_input in div_inputs:
                results.append(self.cp4tsn.solve(div_input))
        calc_time = time.perf_counter() - start_time

        # merge results
        total_route_length = 0
        num_down_locs = np.zeros(self.cp4tsn.T)
        for result in results:
            total_route_length += result["total_route_length"]
            num_down_locs += np.array(result["num_down_locs"])
        num_down = np.mean(num_down_locs)
        down_rate = num_down / num_locs
        objective_value = total_route_length / num_vehicles + self.cp4tsn.loss_coef * down_rate
        # print(f"calc_time = {calc_time}")
        # print(f"route_len = {total_route_length}")
        # print(f"down_rate = {down_rate}")
        # print(f"obj. = {objective_value}")

        avg_actual_tour_length = (total_route_length / num_vehicles) * input["grid_scale"].item()

        summary = {
            "avg_actual_tour_length": avg_actual_tour_length,
            "avg_num_down": num_down,
            "avg_down": down_rate,
            "avg_obj": objective_value,
            "total_calc_time": calc_time
        }

        #
        dir_name = os.path.dirname(log_fname)
        os.makedirs(f"{dir_name}/batch0-sample0", exist_ok=True)

        # save summary
        with open(log_fname, "w") as f:
            json.dump(summary, f)

        # save history
        history = {
            "time": np.arange(self.cp4tsn.T) * self.cp4tsn.dt,
            "down_loc": num_down_locs.tolist()
        }
        with open(f"{dir_name}/batch0-sample0/history_data.pkl", "wb") as f:
            pickle.dump(history, f)

        return calc_time

